%
%  untitled
%
%  Created by Parham Aram on 2010-07-14.
%  Copyright (c) 2010 . All rights reserved.
%
\documentclass[]{article}

% Use utf-8 encoding for foreign characters
\usepackage[utf8]{inputenc}

% Setup for fullpage use
\usepackage{fullpage}

% Uncomment some of the following if you use the features
%
% Running Headers and footers
%\usepackage{fancyhdr}

% Multipart figures
%\usepackage{subfigure}

% More symbols
\usepackage{amsmath}
\usepackage{amssymb}
%\usepackage{latexsym}

% Surround parts of graphics with box
\usepackage{boxedminipage}

% Package for including code in the document
\usepackage{listings}

% If you want to generate a toc for each chapter (use with book)
\usepackage{minitoc}

% This is now the recommended way for checking for PDFLaTeX:
\usepackage{ifpdf}

%\newif\ifpdf
%\ifx\pdfoutput\undefined
%\pdffalse % we are not running PDFLaTeX
%\else
%\pdfoutput=1 % we are running PDFLaTeX
%\pdftrue
%\fi

\ifpdf
\usepackage[pdftex]{graphicx}
\else
\usepackage{graphicx}
\fi
% \title{S1: Extended Derivations for `A Data Driven Framework for Patient-Specific Neural Field Modelling'}
% \author{Dean R. Freestone$^{1,2,3,\ast}$, 
% Parham Aram$^{4}$, 
% Michael Dewar$^{5}$,\\
% Kenneth Scerri$^{6}$,
% David B. Grayden$^{1}$,
% Visakan Kadirkamanathan$^{4}$}
\usepackage{xr}
\usepackage{color}
\newcommand{\dean}[1]{\textsf{\emph{\textbf{\textcolor{red}{#1}}}}}

\externaldocument{DataPaper}

\begin{document}

\ifpdf
\DeclareGraphicsExtensions{.pdf, .jpg, .tif}
\else
\DeclareGraphicsExtensions{.eps, .jpg}
\fi

\renewcommand{\theequation}{S1.\arabic{equation}}




\section*{Product of two $n$-dimensional Gaussian functions}\label{sec:GaussianProduct} 
In this section, we provide a derivation for the product of two n-dimensional Gaussian basis functions.
This derivation is used in the  calculation of $\boldsymbol\lambda_t^{(i)}$  defined in equation \eqref{eq:lambdat} of the main text. Consider two
Gaussian basis functions
\begin{equation}\label{eq:n_dimensional_Gaussian1}
 \varphi_i(\mathbf r)=\mathrm{exp}\left({-\frac{1}{\sigma_i^2} (\mathbf r-\boldsymbol \mu_i)^\top(\mathbf r-\boldsymbol \mu_i})\right)
\end{equation}
and 
\begin{equation}\label{eq:n_dimensional_Gaussian2}
\varphi_j(\mathbf r)=\mathrm{exp}\left({-\frac{1}{\sigma_j^2} (\mathbf r-\boldsymbol \mu_j)^\top(\mathbf r-\boldsymbol \mu_j})\right).
\end{equation}
the product of two Gauusian basis functions is given by
\begin{equation}
 \varphi_i(\mathbf r)\varphi_j(\mathbf r)=\mathrm{exp}\left(-\left[ {\frac{1}{\sigma_i^2} (\mathbf r-\boldsymbol \mu_i)^\top(\mathbf r-\boldsymbol\mu_i)+{\frac{1}{\sigma_j^2} (\mathbf r-\boldsymbol \mu_j)^\top(\mathbf r-\boldsymbol\mu_j)}}\right] \right)
\end{equation}
the product is expanded to give
\begin{align} 
 \varphi_i(\mathbf r)\varphi_j(\mathbf r)&=\mathrm{exp}\left(-\left[ \frac{(\sigma_i^2+\sigma_j^2)\left[\mathbf r^\top\mathbf r-2\mathbf r^\top \frac{\sigma_j^2\boldsymbol\mu_i+\sigma_i^2\boldsymbol\mu_j}{\sigma_i^2+\sigma_j^2}+\frac{(\sigma_j^2\boldsymbol\mu_i+\sigma_i^2\boldsymbol\mu_j)^\top(\sigma_j^2\boldsymbol\mu_i+\sigma_i^2\boldsymbol\mu_j)}{(\sigma_i^2+\sigma_j^2)^2}   \right]  +\frac{\sigma_i^2\sigma_j^2}{\sigma_i^2+\sigma_j^2}(\boldsymbol \mu_i-\boldsymbol\mu_j)^\top(\boldsymbol \mu_i-\boldsymbol\mu_j) }{\sigma_i^2\sigma_j^2}\right] \right) \nonumber\\
&=\mathrm{exp}\left(-\frac{(\sigma_i^2+\sigma_j^2)\left[(\mathbf r-\frac{\sigma_j^2\boldsymbol\mu_i+\sigma_i^2\boldsymbol\mu_j}{\sigma_i^2+\sigma_j^2})^\top(\mathbf r-\frac{\sigma_j^2\boldsymbol\mu_i+\sigma_i^2\boldsymbol\mu_j}{\sigma_i^2+\sigma_j^2})\right]  }{\sigma_i^2\sigma_j^2}\right)
\times\mathrm{exp}\left(-\frac{(\boldsymbol \mu_i-\boldsymbol\mu_j)^\top(\boldsymbol \mu_i-\boldsymbol\mu_j)}{\sigma_i^2+\sigma_j^2}\right)
\end{align}
therefore we have
\begin{equation}
 \varphi_i(\mathbf r)\varphi_j(\mathbf r)=c_{i,j}\times\mathrm{exp}\left({-\frac{1}{\sigma^2} (\mathbf r-\boldsymbol \mu)^\top(\mathbf r-\boldsymbol\mu)}\right)
\end{equation}
where
\begin{equation}
 c_{i,j}=\mathrm{exp}\left(-\frac{(\boldsymbol \mu_i-\boldsymbol\mu_j)^\top(\boldsymbol \mu_i-\boldsymbol\mu_j)}{\sigma_i^2+\sigma_j^2}\right) \quad \sigma^2=\frac{\sigma_i^2\sigma_j^2}{\sigma_i^2+\sigma_j^2}
\end{equation}
and
\begin{equation}
 \boldsymbol\mu=\frac{\sigma_j^2\boldsymbol\mu_i+\sigma_i^2\boldsymbol\mu_j}{\sigma_i^2+\sigma_j^2}
\end{equation}
\section*{Derivative of the firing rate}\label{sec:FiringrateDerivative} 
Here we find the derivative of the activation function which is used to linearize  $q\left(\mathbf x_t\right)$ as described in equation \ref{eq:qTaylor} of the main text. The sigmoidal activation function which relates firing rate of the presynaptic neurons to the post-synaptic membrane potential is given by
\begin{equation}
	\label{ActivationFunction} f\left( v\left( \mathbf{r}', t \right) \right) = \frac{1}{1 + \exp \left( \varsigma \left( v_0 - v\left(\mathbf{r}',t\right) \right) \right)}. 
\end{equation}
Derivative of the sigmoidal activation function can be written in a simple form as
\begin{eqnarray}
 \frac{df}{dv}&=& \frac{\varsigma}{\left(1 + \exp \left( \varsigma \left( v_0 - v\left(\mathbf{r}',t\right) \right) \right)\right)^2} \times \exp \left( \varsigma \left( v_0 - v\left(\mathbf{r}',t\right) \right) \right) \nonumber \\
&=&\frac{\varsigma}{1 + \exp \left( \varsigma \left( v_0 - v\left(\mathbf{r}',t\right) \right) \right)} \times \left(1-\frac{1}{1 + \exp \left( \varsigma \left( v_0 - v\left(\mathbf{r}',t\right) \right) \right)}\right) \nonumber \\
&=& \varsigma f(\boldsymbol \phi^\top(\mathbf r')\mathbf {x}_t)\left( 1-f( \boldsymbol \phi^\top(\mathbf r')\mathbf {x}_t)\right)
\end{eqnarray}
\section*{$\Xi$-variables}\label{sec:Xivariables} 
In this section, we provide derivation for $\Xi$-variables, which we use in the M-step. 
\subsection*{Calculating $\Xi_{0}, \Xi_{1}$ and $\Xi_{2}$}
The expressions for $\Xi_{0}$, $\Xi_{1}$ and $\Xi_{2}$ in terms of smoother outputs can be found in \cite{Shumway2000}, here we present the derivation for completeness.
The expression for  $\Xi_{0}$ as defined in equation~\ref{eq:defofXi0} of the main text is given by
\begin{equation}\label{eq:Xi0}
 \Xi_0=\mathbf E_{\Theta'}\left[\sum_{t=0}^{T-1}\mathbf x_{t+1}\mathbf x_{t+1}^\top\right].
\end{equation}
We start by expanding the covariance matrix as following
\begin{align}
 \mathbf P_{t+1}&=\mathbf E_{\Theta'}\left[(\mathbf x_{t+1}-\mathbf{\hat x}_{t+1})(\mathbf x_{t+1}-\mathbf{\hat x}_{t+1})^\top\right] \nonumber \\
&=\mathbf E_{\Theta'}\left[\mathbf x_{t+1}\mathbf x_{t+1}^\top\right]-\mathbf E_{\Theta'}\left[\mathbf x_{t+1}\mathbf{\hat x}_{t+1}^\top\right]-\mathbf E_{\Theta'}\left[\mathbf{\hat x}_{t+1}\mathbf x_{t+1}^\top\right]+\mathbf E_{\Theta'}\left[\mathbf{\hat x}_{t+1}\mathbf{\hat x}_{t+1}^\top\right] \nonumber \\
&=\mathbf E_{\Theta'}\left[\mathbf x_{t+1}\mathbf x_{t+1}^\top\right]-\mathbf {\hat x}_{t+1}\mathbf{\hat x}_{t+1}^\top-\mathbf {\hat x}_{t+1}\mathbf{\hat x}_{t+1}^\top+\mathbf {\hat x}_{t+1}\mathbf{\hat x}_{t+1}^\top \nonumber \\
&=\mathbf E_{\theta'}\left[\mathbf x_{t+1}\mathbf x_{t+1}^\top\right]-\mathbf {\hat x}_{t+1}\mathbf{\hat x}_{t+1}^\top,
\end{align}
therefore we can write
\begin{equation}\label{eq:Xi0derivation1}
 \mathbf E_{\Theta'}\left[\mathbf x_{t+1}\mathbf x_{t+1}^\top\right]=\mathbf P_{t+1}+\mathbf {\hat x}_{t+1}\mathbf{\hat x}_{t+1}^\top,
\end{equation}
substituting \ref{eq:Xi0derivation1} in \ref{eq:Xi0} we get
\begin{equation}
 \Xi_0=\sum_{t=0}^{T-1}\left(\mathbf P_{t+1}+\mathbf{\hat x}_{t+1}\mathbf{\hat x}_{t+1}^\top\right).
\end{equation}
To calculate $\Xi_1$, from equation~\ref{eq:defofXi1} of the main text we have
\begin{equation}\label{eq:Xi1}
 \Xi_1=\mathbf E_{\Theta'}\left[\sum_{t=0}^{T-1}\mathbf x_t\mathbf x_{t+1}^\top\right].
\end{equation}
An expression for $\Xi_1$ in terms of the smoothed states can be also found in a similar way by expanding the cross-covariance matrix,
\begin{align}
 \mathbf M_{t+1}&=\mathbf E_{\Theta'}\left[(\mathbf x_t-\mathbf{\hat x}_t)(\mathbf x_{t+1}-\mathbf{\hat x}_{t+1})^\top\right] \nonumber \\
&=\mathbf E_{\Theta'}\left[\mathbf x_t\mathbf x_{t+1}^\top\right]-\mathbf {\hat x}_t\mathbf{\hat x}_{t+1}^\top
\end{align}
therefore we can write
\begin{equation}\label{eq:Xi1derivation1}
 \mathbf E_{\Theta'}\left[\mathbf x_t\mathbf x_{t+1}^\top\right]=\mathbf M_{t+1}+\mathbf {\hat x}_t\mathbf{\hat x}_{t+1}^\top
\end{equation}
substituting \ref{eq:Xi1derivation1} in \ref{eq:Xi1} we get
\begin{equation}
 \Xi_1=\sum_{t=0}^{T-1}\left(\mathbf M_{t+1}+\mathbf{\hat x}_t\mathbf{\hat x}_{t+1}^\top\right)
\end{equation}


 The expression for $\Xi_2$ can be simply found by changing $t+1$ to $t$ in $\Xi_0$.

\subsection*{Calculating $\Xi_{3},\Xi_{4}$ and $\Xi_{5}$}
In this section we calculate $\Xi$-variables needed for approximating non-linear terms in $\mathcal{Q}$-function, terms including $q\left(\mathbf x_t\right)$, using the approximation given in equation \ref{eq:qTaylor} on page \pageref{eq:qTaylor} of the main text.

The third term of equation \ref{eq:Qfunctiontrace2} on page \pageref{eq:Qfunctiontrace2} can be approximated as following, 
\begin{align}\label{eq:Xi3Derivation1}
 \mathbf x_{t+1}^\top\tilde{\boldsymbol\Sigma}_e^{-1}q( \mathbf x_t) &\approx  \mathbf x_{t+1}^\top\tilde{\boldsymbol\Sigma}_e^{-1}\left[q(\mathbf {\hat x}_t)+\int_\Omega \boldsymbol{\Psi}(\mathbf{r}')\boldsymbol \phi^\top(\mathbf r') (\mathbf x_t - \mathbf  {\hat x}_t)f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}'\right] \nonumber \\
&=\mathbf x_{t+1}^\top\tilde{\boldsymbol\Sigma}_e^{-1}q(\mathbf {\hat x}_t)+\mathbf x_{t+1}^\top\tilde{\boldsymbol\Sigma}_e^{-1}\int_\Omega \boldsymbol{\Psi}(\mathbf{r}')\boldsymbol \phi^\top(\mathbf r') (\mathbf x_t - \mathbf  {\hat x}_t)f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}'
\end{align}
noting that $\phi^\top(\mathbf r') (\mathbf x_t - \mathbf  {\hat x}_t)$ is a scalar we can write \ref{eq:Xi3Derivation1} as 
\begin{eqnarray}\label{eq:Xi3Derivation2}
 \mathbf x_{t+1}^\top\tilde{\boldsymbol\Sigma}_e^{-1}q( \mathbf x_t) &\approx& \mathbf x_{t+1}^\top\tilde{\boldsymbol\Sigma}_e^{-1}q(\mathbf {\hat x}_t)+\int_\Omega \boldsymbol \phi^\top(\mathbf r') (\mathbf x_t - \mathbf  {\hat x}_t)\mathbf x_{t+1}^\top\tilde{\boldsymbol\Sigma}_e^{-1}    \boldsymbol{\Psi}(\mathbf{r}')f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}'
\end{eqnarray}
taking expected value of \ref{eq:Xi3Derivation2} we get 
\begin{align}\label{eq:Xi3Derivation3}
 \mathbf E_{\boldsymbol\Theta'}\left[\mathbf x_{t+1}^\top\tilde{\boldsymbol\Sigma}_e^{-1}q( \mathbf x_t)\right] &\approx \mathbf E_{\boldsymbol\Theta'}\left[\mathbf x_{t+1}^\top\right]\tilde{\boldsymbol\Sigma}_e^{-1}q(\mathbf {\hat x}_t) \nonumber \\
&+\int_\Omega \boldsymbol \phi^\top(\mathbf r')  \mathbf E_{\boldsymbol\Theta'}\left[(\mathbf x_t - \mathbf  {\hat x}_t)\mathbf x_{t+1}^\top\right]\tilde{\boldsymbol\Sigma}_e^{-1}    \boldsymbol{\Psi}(\mathbf{r}')f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}' 
\end{align}
Substituting for  $\mathbf E_{\boldsymbol\Theta'}\left[(\mathbf x_t - \mathbf  {\hat x}_t)\mathbf x_{t+1}^\top\right]$ from equation ~\ref{eq:Xi1derivation1} and summing over $t \in \left\lbrace 0, \dots, T-1\right\rbrace $ yields
\begin{equation}
\Xi_3=\sum_{t=0}^{T-1}\left[ \mathbf{\hat x}_{t+1}^\top\tilde{\boldsymbol\Sigma}_e^{-1}q(\mathbf{\hat x}_t)+\int_\Omega\boldsymbol \phi^\top(\mathbf r') \mathbf M_{t+1} \tilde{\boldsymbol\Sigma}_e^{-1}  \boldsymbol{\Psi}(\mathbf{r}') f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}'\right] \\	
\end{equation}

\subsection*{Calculating $\Xi_{4}$}
In order to find an approximation for the fifth term in equation \ref{eq:Qfunctiontrace2} of the main text we can write
\begin{align}\label{eq:Xi4derivation1}
 q^\top(\mathbf x_t)\tilde{\boldsymbol\Sigma}_e^{-1}q(\mathbf x_t)&\approx \left[ q(\mathbf {\hat x}_t)+\int_\Omega \boldsymbol{\Psi}(\mathbf{r}')\boldsymbol \phi^\top(\mathbf r') (\mathbf x_t - \mathbf  {\hat x}_t)f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}'\right]^\top  \times \tilde{\boldsymbol\Sigma}_e^{-1}\nonumber \\
&\times\left[ q(\mathbf {\hat x}_t)+\int_\Omega \boldsymbol{\Psi}(\mathbf{r}')\boldsymbol \phi^\top(\mathbf r') (\mathbf x_t - \mathbf  {\hat x}_t)f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}'\right] \nonumber \\
&= \mathrm{term1} + \mathrm{term2} + \mathrm{term3} + \mathrm{term4}
\end{align}
where
\begin{align}
  \mathrm{term1}&=q^\top(\mathbf {\hat x}_t)\tilde{\boldsymbol\Sigma}_e^{-1}q(\mathbf {\hat x}_t)
\end{align}
\begin{align}
\mathrm{term2}=&q^\top(\mathbf {\hat x}_t)\tilde{\boldsymbol\Sigma}_e^{-1}\int_\Omega \boldsymbol{\Psi}(\mathbf{r}')\boldsymbol \phi^\top(\mathbf r') (\mathbf x_t - \mathbf  {\hat x}_t)f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}'
 \end{align}
\begin{align}
\mathrm{term3}=&\int_\Omega \boldsymbol{\Psi}^\top(\mathbf{r}')\boldsymbol \phi^\top(\mathbf r') (\mathbf x_t - \mathbf  {\hat x}_t)f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}'\tilde{\boldsymbol\Sigma}_e^{-1}q(\mathbf {\hat x}_t)
\end{align}
\begin{align}
 \mathrm{term4} &=\int_\Omega \boldsymbol{\Psi}^\top(\mathbf{r}')\boldsymbol \phi^\top(\mathbf r') (\mathbf x_t - \mathbf  {\hat x}_t)f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}' \times \tilde{\boldsymbol  \Sigma}_e^{-1} \nonumber \\
&\times \int_\Omega \boldsymbol{\Psi}(\mathbf{r}')\boldsymbol \phi^\top(\mathbf r') (\mathbf x_t - \mathbf  {\hat x}_t)f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}' 
\end{align}
It should be noted that when applying expectation, term1 is constant, and term2 and term3 disapears as $\mathbf E_{\Theta'}\left[(\mathbf x_t - \mathbf  {\hat x}_t)\right]= \mathbf 0$.

\dean{Motivate the step: To use the covariance estimate from the filter we need to get the $\mathbf{x}_t$ terms together.} To do this the last term on the right hand side of equation \ref{eq:Xi4derivation1} can be rewritten as (\dean{we should talk about this in words and go direct to the next equation})
\begin{align}
 term4 &= \int_\Omega \boldsymbol{\Psi}^\top(\mathbf{r}')f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) \boldsymbol \phi^\top(\mathbf r')(\mathbf x_t - \mathbf  {\hat x}_t)d\mathbf{r}' \times \tilde{\boldsymbol\Sigma}_e^{-1} \times\int_\Omega  (\mathbf x_t - \mathbf  {\hat x}_t)^\top\boldsymbol \phi(\mathbf r') \boldsymbol{\Psi}(\mathbf{r}')f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}'& \nonumber \\
&=\sum_{i,j=1}^{n_x}{\boldsymbol\lambda}_t^{(i)\top}(\mathbf x_{i,t} - \mathbf  {\hat x}_{i,t})(\mathbf x_{j,t} - \mathbf  {\hat x}_{j,t})\tilde{\boldsymbol\Sigma}_e^{-1}{\boldsymbol\lambda}_t^{(j)}
\end{align}
where
\begin{align}
	{\boldsymbol \lambda}_t^{(i)}&=\int_{\Omega} \boldsymbol \Psi(\mathbf r')\phi_i(\mathbf r')f'(\boldsymbol\phi^\top(\mathbf r')\mathbf {\hat x}_t)d\mathbf r' \label{eq:lambdatildei}
\end{align}
therefore term4 can be written in a form of
\begin{align}\label{eq:Xi4derivation2}
  \mathrm{term4}&= q^\top(\mathbf {\hat x}_t)\tilde{\boldsymbol\Sigma}_e^{-1}q(\mathbf {\hat x}_t)+\sum_{i,j=1}^{n_x}{\boldsymbol\lambda}_t^{(i)\top}(\mathbf x_{i,t} - \mathbf  {\hat x}_{i,t})(\mathbf x_{j,t} - \mathbf  {\hat x}_{j,t})\tilde{\boldsymbol\Sigma}_e^{-1}{\boldsymbol\lambda}_t^{(j)}
\end{align}
taking expectation from \eqref{eq:Xi4derivation2}  and noting $\mathbf E_{\boldsymbol\theta'}\left[(\mathbf x_{i,t} - \mathbf  {\hat x}_{i,t})(\mathbf x_{j,t} - \mathbf  {\hat x}_{j,t}) \right]=\left[\mathbf{P}_t\right]_{i,j} $ gives
\begin{align}
 \mathrm{term4}&= q^\top(\mathbf {\hat x}_t)\tilde{\boldsymbol\Sigma}_e^{-1}q(\mathbf {\hat x}_t)+\boldsymbol\Lambda_t
\end{align}
where
\begin{equation}
 \boldsymbol\Lambda_t=\sum_{i,j=1}^{n_x}[\mathbf{P_t}]_{ij}{\boldsymbol\lambda}_t^{(i)\top}\tilde{\boldsymbol\Sigma}_e^{-1}{\boldsymbol\lambda}_t^{(j)}
\end{equation}

\subsection*{Calculating $\Xi_{5}$}
The last term of equation \ref{eq:Qfunctiontrace2} on page \pageref{eq:Qfunctiontrace2} can be approximated as following, 
\begin{align}\label{eq:Xi5derivation1}
 \mathbf x_t^\top\tilde{\boldsymbol\Sigma}_e^{-1}q(\mathbf x_t)&\approx\mathbf x_t^\top\tilde{\boldsymbol\Sigma}_e^{-1}\left[q(\mathbf {\hat x}_t)+\int_\Omega \boldsymbol{\Psi}(\mathbf{r}')\boldsymbol \phi^\top(\mathbf r') (\mathbf x_t - \mathbf  {\hat x}_t)f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}'\right] \nonumber\\
&=\mathbf x_t^\top\tilde{\boldsymbol\Sigma}_e^{-1}q(\mathbf {\hat x}_t)+\mathbf x_t^\top\tilde{\boldsymbol\Sigma}_e^{-1}\int_\Omega \boldsymbol{\Psi}(\mathbf{r}')\boldsymbol \phi^\top(\mathbf r') (\mathbf x_t - \mathbf  {\hat x}_t)f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}' \nonumber \\
&=\mathbf x_t^\top\tilde{\boldsymbol\Sigma}_e^{-1}q(\mathbf {\hat x}_t)+\int_\Omega \boldsymbol \phi^\top(\mathbf r') (\mathbf x_t - \mathbf  {\hat x}_t)\mathbf x_t^\top\tilde{\boldsymbol\Sigma}_e^{-1}\boldsymbol{\Psi}(\mathbf{r}')f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}'
\end{align}
taking expected value of \ref{eq:Xi5derivation1} we get
\begin{align}\label{eq:Xi5derivation2}
\mathbf E_{\Theta'}\left[\mathbf x_t^\top\boldsymbol\Sigma_e^{-1}q(\mathbf x_t)\right]&\approx\mathbf E_{\Theta'}\left[\mathbf x_t^\top\right]\tilde{\boldsymbol\Sigma}_e^{-1}q(\mathbf {\hat x}_t)+\int_\Omega \boldsymbol \phi^\top(\mathbf r') \mathbf E_{\Theta'}\left[(\mathbf x_t - \mathbf  {\hat x}_t)\mathbf x_t^\top\right]\tilde{\boldsymbol\Sigma}_e^{-1}\boldsymbol{\Psi}(\mathbf{r}')f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}' 
\end{align}
substituting for $\mathbf E_{\Theta'}\left[(\mathbf x_t - \mathbf  {\hat x}_t)\mathbf x_t^\top\right] $ from equation \ref{eq:Xi0derivation1} and summing over $t \in \left\lbrace 0, \dots, T-1\right\rbrace $ we get
\begin{equation}
\Xi_5=\sum_{t=0}^{T-1}\left[\mathbf{ \hat x}_t^\top\tilde{\boldsymbol\Sigma}_e^{-1}q(\mathbf {\hat x}_t)+\int_\Omega \boldsymbol \phi^\top(\mathbf r') \mathbf P_t\tilde{\boldsymbol\Sigma}_e^{-1}\boldsymbol{\Psi}(\mathbf{r}')f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}' \right] \\	
\end{equation}
% \subsection*{Calculating $\Xi_{5}$}
% We have
% \begin{equation}\label{eq:Xi5}
%  \Xi_5=\mathbf E_{\Theta'}\left[\sum_{t=0}^{T-1}\mathbf x_t\mathbf x_{t}^\top\right]
% \end{equation}
% To find an expression for $\Xi_5$ in terms of smoother outputs we start by expanding the covariance matrix as following
% \begin{eqnarray}
%  \mathbf P_{t}&=&\mathbf E_{\Theta'}\left[(\mathbf x_t-\mathbf{\hat x}_t)(\mathbf x_{t}-\mathbf{\hat x}_{t})^\top\right] \nonumber \\
% &=&\mathbf E_{\Theta'}\left[\mathbf x_t\mathbf x_{t}^\top\right]-\mathbf E_{\Theta'}\left[\mathbf x_t\mathbf{\hat x}_{t}^\top\right]-\mathbf E_{\Theta'}\left[\mathbf{\hat x}_t\mathbf x_{t}^\top\right]+\mathbf E_{\Theta'}\left[\mathbf{\hat x}_t\mathbf{\hat x}_{t}^\top\right] \nonumber \\
% &=&\mathbf E_{\Theta'}\left[\mathbf x_t\mathbf x_{t}^\top\right]-\mathbf {\hat x}_t\mathbf{\hat x}_{t}^\top-\mathbf {\hat x}_t\mathbf{\hat x}_{t}^\top+\mathbf {\hat x}_t\mathbf{\hat x}_{t}^\top \nonumber \\
% &=&\mathbf E_{\theta'}\left[\mathbf x_t\mathbf x_{t}^\top\right]-\mathbf {\hat x}_t\mathbf{\hat x}_{t}^\top
% \end{eqnarray}
% therefore we can write
% \begin{equation}\label{eq:Xi5derivation1}
%  \mathbf E_{\Theta'}\left[\mathbf x_t\mathbf x_{t}^\top\right]=\mathbf P_{t}+\mathbf {\hat x}_t\mathbf{\hat x}_{t}^\top
% \end{equation}
% substituting \ref{eq:Xi5derivation1} in \ref{eq:Xi5} we get
% \begin{equation}
%  \Xi_5=\sum_{t=0}^{T-1}\left(\mathbf P_{t}+\mathbf{\hat x}_t\mathbf{\hat x}_{t}^\top\right)
% \end{equation}



%############################################################
% \section*{$\sigma_e^2$ Estimation}\label{sec:sigmaeEstimation} 
% we have
% \begin{equation}\label{eq:qTaylor}
%  q(\mathbf x_t) \approx q(\mathbf {\hat x}_t)+\int_\Omega \boldsymbol{\Psi}(\mathbf{r}')\boldsymbol \phi^\top(\mathbf r') (\mathbf x_t - \mathbf  {\hat x}_t)f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}'
% \end{equation}
% \begin{eqnarray}
%  p(\mathbf x_{t+1}, \mathbf y_{t+1};\boldsymbol\Theta)&=& \mid\boldsymbol\Sigma_{\epsilon}\mid^{-\frac{1}{2}} \times  e^{-\frac{1}{2}(\mathbf y_{t+1}-\mathbf C\mathbf  x_{t+1})^\top\boldsymbol\Sigma_{\epsilon}^{-1}(\mathbf y_{t+1}-\mathbf C\mathbf  x_{t+1}) } \nonumber \\
% &+&  \mid\boldsymbol\Sigma_e\mid^{-\frac{1}{2}} \times e^{-\frac{1}{2}(\mathbf x_{t+1}-q(\mathbf  x_t)\boldsymbol\theta-\xi  \mathbf x_t)^\top\boldsymbol\Sigma_e^{-1}(\mathbf x_{t+1}-q( \mathbf x_t)\boldsymbol\theta-\xi \mathbf  x_t)}
% \end{eqnarray}
% by expanding the exponent and taking $2\log$ we get
% \begin{eqnarray}\label{eq:Qfunction}
% 2\ln p(\mathbf x_{t+1} , \mathbf y_{t+1};\boldsymbol\Theta)&=&-\ln \mid\boldsymbol\Sigma_{\epsilon}\mid- (\mathbf y_{t+1}-\mathbf C\mathbf  x_{t+1})^\top\boldsymbol\Sigma_{\epsilon}^{-1}(\mathbf y_{t+1}-\mathbf C\mathbf  x_{t+1})\nonumber \\
% &-&\ln \mid\boldsymbol\Sigma_e\mid-\mathbf x_{t+1}^\top\boldsymbol\Sigma_e^{-1}\mathbf x_{t+1}+2\mathbf x_{t+1}^\top\boldsymbol\Sigma_e^{-1}q( \mathbf x_t)\boldsymbol\theta+2\xi \mathbf x_{t+1}^\top\boldsymbol\Sigma_e^{-1}\mathbf x_t\nonumber \\
% &-&\boldsymbol\theta^\top q^\top(\mathbf x_t)\boldsymbol\Sigma_e^{-1}q(\mathbf x_t)\boldsymbol\theta-2\xi \mathbf x_t^\top\boldsymbol\Sigma_e^{-1}q(\mathbf x_t)\boldsymbol\theta-\xi^2\mathbf x_t^\top\boldsymbol\Sigma_e^{-1}\mathbf x_t.
% \end{eqnarray}
% Taking trace and rearranging, using the invariant cyclic permutations property of the trace, this distribution can be written as
% \begin{eqnarray}\label{eq:Qfunctionintrace}
%   \ln p(\mathbf x_{t+1}, \mathbf y_{t+1};\boldsymbol\Theta)&=& -\ln \mid\boldsymbol\Sigma_{\epsilon}\mid-\mathrm{tr}\left\lbrace\boldsymbol\Sigma_{\epsilon}^{-1}(\mathbf y_{t+1}-\mathbf C\mathbf  x_{t+1}) (\mathbf y_{t+1}-\mathbf C\mathbf  x_{t+1})^\top\right\rbrace   \nonumber \\
% &-&\ln \mid\boldsymbol\Sigma_e\mid-\mathrm{tr}\left\lbrace\mathbf x_{t+1}\mathbf x_{t+1}^\top\boldsymbol\Sigma_e^{-1}\right\rbrace+2\mathbf x_{t+1}^\top\boldsymbol\Sigma_e^{-1}q( \mathbf x_t)\boldsymbol\theta+2\xi \mathrm{tr} \left\lbrace \mathbf x_t\mathbf x_{t+1}^\top\boldsymbol\Sigma_e^{-1}\right\rbrace \nonumber \\
% &&-\boldsymbol\theta^\top q^\top(\mathbf x_t)\boldsymbol\Sigma_e^{-1}q(\mathbf x_t)\boldsymbol\theta-2\xi \mathbf x_t^\top\boldsymbol\Sigma_e^{-1}q(\mathbf x_t)\boldsymbol\theta-\xi^2\mathrm{tr}\left\lbrace \mathbf x_t \mathbf x_t^\top\boldsymbol\Sigma_e^{-1}\right\rbrace. 
% \end{eqnarray}
% Substituting \ref{eq:qTaylor} in \ref{eq:Qfunctionintrace} and taking the expectation of the log likelihood function for all time instants gives an approximate to the lower-bound that needs to be maximised to gain optimal parameter estimates. We define $\boldsymbol\Sigma_e=\sigma_e^2\tilde{\boldsymbol\Sigma}_e$. Therefore $\mathcal Q$-function can be approximated as  
% \begin{eqnarray}\label{eq:Voldermont}
%  \mathcal Q(\boldsymbol \Theta,\boldsymbol\Theta')&\approx& -(T-1)\ln \mid\boldsymbol\Sigma_{\epsilon}\mid-\mathrm{tr}\left\lbrace\boldsymbol\Sigma_{\epsilon}^{-1}\sum_{t=0}^{T-1}\left[ (\mathbf y_{t+1}-\mathbf C\mathbf{\hat{x}}_{t+1}) (\mathbf y_{t+1}-\mathbf C\mathbf{\hat{x}}_{t+1})^\top+\mathbf C \mathbf P_{t+1}\mathbf C^\top\right] \right\rbrace\nonumber \\
% &-&(T-1)\ln \mid\sigma_e^2\tilde{\boldsymbol\Sigma}_e\mid-\frac{1}{\sigma_e^2}\mathrm{tr}\left\lbrace \Xi'_0 \tilde{\boldsymbol\Sigma}_e^{-1}\right\rbrace +2\frac{1}{\sigma_e^2}\Xi_0\boldsymbol\theta+
% \frac{2\xi}{\sigma_e^2} \mathrm{tr}\left\lbrace \Xi_1 \tilde{\boldsymbol\Sigma}_e^{-1}\right\rbrace \nonumber \\
% &-&\frac{1}{\sigma_e^2}\boldsymbol\theta^\top \Xi_2\boldsymbol\theta-\frac{2\xi}{\sigma_e^2} \Xi_3 \boldsymbol\theta -  \frac{\xi^2}{\sigma_e^2}\mathrm{tr} \left\lbrace\Xi_4\tilde{\boldsymbol\Sigma}_e^{-1} \right\rbrace 
% \end{eqnarray}
% where 
% \begin{align}
% 	\Xi'_0&=\mathbf E_{\Theta'}\left[\sum_{t=0}^{T-1}\mathbf x_{t+1}\mathbf x_{t+1}^\top\right]=\sum_{t=0}^{T-1}\left(\mathbf P_{t+1}+\mathbf{\hat x}_{t+1}\mathbf{\hat x}_{t+1}^\top\right)\label{eq:def of Xi'0} \\
% \Xi_0&=\sum_{t=0}^{T-1}\left[ \mathbf{\hat x}_{t+1}^\top\tilde{\boldsymbol\Sigma}_e^{-1}q(\mathbf{\hat x}_t)+\int_\Omega\boldsymbol \phi^\top(\mathbf r') \mathbf M_{t+1} \tilde{\boldsymbol\Sigma}_e^{-1} \boldsymbol{\Psi}(\mathbf{r}') f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}'\right] \\	
% \Xi_1&=\mathbf E_{\Theta'}\left[\sum_{t=0}^{T-1}\mathbf x_t\mathbf x_{t+1}^\top\right]=\sum_{t=0}^{T-1}\left(\mathbf M_{t+1}+\mathbf{\hat x}_t\mathbf{\hat x}_{t+1}^\top\right) \\
% \Xi_2&=\sum_{t=0}^{T-1}\left[q^\top(\mathbf{\hat x}_t)\tilde{\boldsymbol\Sigma}_e^{-1}q(\mathbf{\hat x}_t)+\Lambda_t(\mathbf r)\mathbf P_t \tilde{\Lambda}_t(\mathbf r)\right] \\
%  \Xi_3&=\sum_{t=0}^{T-1}\left[ \mathbf{\hat x}_{t}^\top\tilde{\boldsymbol\Sigma}_e^{-1}q(\mathbf{\hat x}_t)+\int_\Omega\boldsymbol \phi^\top(\mathbf r') \mathbf P_t \tilde{\boldsymbol\Sigma}_e^{-1}  \boldsymbol{\Psi}(\mathbf{r}') f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}'\right] \\
%  \Xi_4&=\mathbf E_{\Theta'}\left[\sum_{t=0}^{T-1}\mathbf x_t\mathbf x_{t}^\top\right]=\sum_{t=0}^{T-1}\left(\mathbf P_t+\mathbf{\hat x}_t\mathbf{\hat x}_t^\top\right)
% \end{align}
% and
% \begin{align}
% 	 \Lambda_t(\mathbf r)&=\begin{bmatrix}\boldsymbol \lambda_t^{(1)}(\mathbf r) & \boldsymbol \lambda_t^{(2)}(\mathbf r)& \dots &\boldsymbol \lambda_t^{(i)}(\mathbf r)\end{bmatrix} \\
% 	 \boldsymbol\lambda_t^{(i)}(\mathbf r)&=\int_{\Omega} \boldsymbol \Psi^\top(\mathbf r')\tilde{\boldsymbol\Sigma}_e^{-1}\phi_i(\mathbf r')f'(\boldsymbol\phi^\top(\mathbf r')\mathbf {\hat x}_t)d\mathbf r'\\
% 	\tilde{\Lambda}_t(\mathbf r)&=\begin{bmatrix}\tilde{\boldsymbol \lambda}_t^{(1)}(\mathbf r) \\ \tilde{\boldsymbol \lambda}_t^{(2)}(\mathbf r) \\ \vdots \\ \tilde{\boldsymbol \lambda}_t^{(i)}(\mathbf r)\end{bmatrix} \\
% 	 \tilde{\boldsymbol \lambda}_t^{(i)}(\mathbf r)&=\int_{\Omega} \boldsymbol \Psi(\mathbf r')\phi_i(\mathbf r')f'(\boldsymbol\phi^\top(\mathbf r')\mathbf {\hat x}_t)d\mathbf r'
% \end{align}
% It should be noted that the second term in equation \ref{eq:Voldermont} is obtained by adding and subtracting $\mathbf C \mathbf{\hat{x}}_t \mathbf{\hat{x}}_t^\top \mathbf C^\top$ to the expectation, $\mathbf E_{\boldsymbol\Theta'}\left[ .\right] $. Given the state estimates, $\mathbf {\hat x^{b}}_t$ the state covariance $\mathbf P_t^b$ and cross-covariance $\mathbf M_t^b$ , the $\Xi$-variables can be computed directly.
% 
% When taking the derivative of equation~\ref{eq:Voldermont}, the constant $\beta$ described in equation~\ref{eq:def of beta} will disappear. Differntiating with respect to $\boldsymbol\theta$ we have
% \begin{equation}\label{eq:Qpartialtheta}
%  \frac{\partial \mathcal Q}{\partial \boldsymbol\theta}=2\Xi_0-\boldsymbol\theta^\top(\Xi_2^\top+\Xi_2)-2\xi\Xi_3
% \end{equation}
% noting that $\Xi_2$ is symmetric and equating \ref{eq:Qpartialtheta} to the zero vector we get
% \begin{equation}\label{eq:theta}
%  \boldsymbol \theta=\Xi_2^{-1}\left(\Xi_0^\top-\xi\Xi_3^\top \right)
% \end{equation}
% similarly differentiating with respect to $\xi$ we have
% \begin{equation}\label{eq:Qpartialxi}
%  \frac{\partial \mathcal Q}{\partial \xi}=2tr\left\lbrace \Xi_1 \boldsymbol\Sigma_e^{-1}\right\rbrace -2 \Xi_3 \boldsymbol\theta - 2\xi tr \left\lbrace\Xi_4\boldsymbol\Sigma_e^{-1} \right\rbrace
% \end{equation}
% substituting \ref{eq:theta} in \ref{eq:Qpartialxi} and equating to zero we get
% \begin{equation}
%  \xi=\frac{tr\left\lbrace \Xi_1 \tilde{\boldsymbol\Sigma}_e^{-1}\right\rbrace-\Xi_3\Xi_2^{-1}\Xi_0^\top}{tr\left\lbrace \Xi_4 \tilde{\boldsymbol\Sigma}_e^{-1}\right\rbrace-\Xi_3\Xi_2^{-1}\Xi_3^\top}
% \end{equation}
% Rewrite equation~\ref{eq:Voldermont} as
% \begin{equation}
%  \mathcal Q(\boldsymbol \Theta,\boldsymbol\Theta')\propto-(T-1)n_y\ln\sigma^2_{\epsilon}-\frac{1}{\sigma_{\epsilon}^2}\mathrm{tr}\left\lbrace\sum_{t=0}^{T-1}\left[ (\mathbf y_{t+1}-\mathbf C\mathbf{\hat{x}}_{t+1}) (\mathbf y_{t+1}-\mathbf C\mathbf{\hat{x}}_{t+1})^\top+\mathbf C \mathbf P_{t+1}\mathbf C^\top\right] \right\rbrace
% \end{equation}
% differentiating with respect to $\sigma_{\epsilon}^2$
% \begin{equation}
%   \frac{\partial \mathcal Q}{\partial \sigma_{\epsilon}^2}=-(T-1)n_y\frac{1}{\sigma_{\epsilon}^2}+\frac{1}{\sigma_{\epsilon}^4}\mathrm{tr}\left\lbrace\sum_{t=0}^{T-1}\left[ (\mathbf y_{t+1}-\mathbf C\mathbf{\hat{x}}_{t+1}) (\mathbf y_{t+1}-\mathbf C\mathbf{\hat{x}}_{t+1})^\top+\mathbf C \mathbf P_{t+1}\mathbf C^\top\right] \right\rbrace
% \end{equation}
% setting above to zero and solving for $\sigma_{\epsilon}^2$ we have
% \begin{equation}
%  \sigma_{\epsilon}^2=\frac{1}{(T-1)n_y}\sum_{t=0}^{T-1}\mathrm{tr}\left\lbrace (\mathbf y_{t+1}-\mathbf C\mathbf{\hat{x}}_{t+1}) (\mathbf y_{t+1}-\mathbf C\mathbf{\hat{x}}_{t+1})^\top+\mathbf C \mathbf P_{t+1}\mathbf C^\top \right\rbrace
% \end{equation}
% differentiating ~\ref{eq:Voldermont} with respect to $\sigma_e^2$ we have
% \begin{eqnarray}
%  \frac{\partial \mathcal Q}{\partial \sigma_e^2}&=& -(T-1)n_x\frac{1}{\sigma_e^2}+\frac{1}{\sigma_e^4}\mathrm{tr}\left\lbrace \Xi'_0 \tilde{\boldsymbol\Sigma}_e^{-1}\right\rbrace -2\frac{1}{\sigma_e^4}\Xi_0\boldsymbol\theta-
% \frac{2\xi}{\sigma_e^4} \mathrm{tr}\left\lbrace \Xi_1 \tilde{\boldsymbol\Sigma}_e^{-1}\right\rbrace \nonumber \\
% &+&\frac{1}{\sigma_e^4}\boldsymbol\theta^\top \Xi_2\boldsymbol\theta+\frac{2\xi}{\sigma_e^4} \Xi_3 \boldsymbol\theta +\frac{\xi^2}{\sigma_e^4}\mathrm{tr} \left\lbrace\Xi_4\tilde{\boldsymbol\Sigma}_e^{-1} \right\rbrace 
% \end{eqnarray}
% setting above to zero and solving for $\sigma_e^2$ we have
% \begin{eqnarray}
% \sigma_e^2=\frac{1}{(T-1)n_x}\left[ \mathrm{tr}\left\lbrace \Xi'_0 \tilde{\boldsymbol\Sigma}_e^{-1}\right\rbrace -2\Xi_0\boldsymbol\theta-
% 2\xi\mathrm{tr}\left\lbrace \Xi_1 \tilde{\boldsymbol\Sigma}_e^{-1}\right\rbrace+\boldsymbol\theta^\top \Xi_2\boldsymbol\theta+2\xi\Xi_3 \boldsymbol\theta +\xi^2\mathrm{tr} \left\lbrace\Xi_4\tilde{\boldsymbol\Sigma}_e^{-1} \right\rbrace \right] 
% \end{eqnarray}


\bibliographystyle{plain}
\bibliography{EMIDE}
\end{document}

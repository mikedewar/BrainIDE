%
%  untitled
%
%  Created by Parham Aram on 2010-07-14.
%  Copyright (c) 2010 . All rights reserved.
%
\documentclass[]{article}

% Use utf-8 encoding for foreign characters
\usepackage[utf8]{inputenc}

% Setup for fullpage use
\usepackage{fullpage}

% Uncomment some of the following if you use the features
%
% Running Headers and footers
%\usepackage{fancyhdr}

% Multipart figures
%\usepackage{subfigure}

% More symbols
\usepackage{amsmath}
\usepackage{amssymb}
%\usepackage{latexsym}

% Surround parts of graphics with box
\usepackage{boxedminipage}

% Package for including code in the document
\usepackage{listings}

% If you want to generate a toc for each chapter (use with book)
\usepackage{minitoc}

% This is now the recommended way for checking for PDFLaTeX:
\usepackage{ifpdf}

%\newif\ifpdf
%\ifx\pdfoutput\undefined
%\pdffalse % we are not running PDFLaTeX
%\else
%\pdfoutput=1 % we are running PDFLaTeX
%\pdftrue
%\fi

\ifpdf
\usepackage[pdftex]{graphicx}
\else
\usepackage{graphicx}
\fi
% \title{S1: Extended Derivations for `A Data Driven Framework for Patient-Specific Neural Field Modelling'}
% \author{Dean R. Freestone$^{1,2,3,\ast}$, 
% Parham Aram$^{4}$, 
% Michael Dewar$^{5}$,\\
% Kenneth Scerri$^{6}$,
% David B. Grayden$^{1}$,
% Visakan Kadirkamanathan$^{4}$}


\begin{document}

\ifpdf
\DeclareGraphicsExtensions{.pdf, .jpg, .tif}
\else
\DeclareGraphicsExtensions{.eps, .jpg}
\fi

\renewcommand{\theequation}{S1.\arabic{equation}}
\section*{Product of two $n$-dimensional Gaussian functions}\label{sec:GaussianProduct} 
In this section, we provide a derivation for the product of two n-dimensional Gaussian basis functions.
This derivation is used in the  calculation of $\nabla 	q$. Consider two
Gaussian basis functions
\begin{equation}\label{eq:n_dimensional_Gaussian1}
 \varphi_i(\mathbf r)=\mathrm{exp}\left({-\frac{1}{\sigma_i^2} (\mathbf r-\boldsymbol \mu_i)^\top(\mathbf r-\boldsymbol \mu_i})\right)
\end{equation}
and 
\begin{equation}\label{eq:n_dimensional_Gaussian2}
\varphi_j(\mathbf r)=\mathrm{exp}\left({-\frac{1}{\sigma_j^2} (\mathbf r-\boldsymbol \mu_j)^\top(\mathbf r-\boldsymbol \mu_j})\right).
\end{equation}
the product of two Gauusian basis functions is given by
\begin{equation}
 \varphi_i(\mathbf r)\varphi_j(\mathbf r)=\mathrm{exp}-\left({\frac{1}{\sigma_i^2} (\mathbf r-\boldsymbol \mu_i)^\top(\mathbf r-\boldsymbol\mu_i)+{\frac{1}{\sigma_j^2} (\mathbf r-\boldsymbol \mu_j)^\top(\mathbf r-\boldsymbol\mu_j)}}\right)
\end{equation}
the product is expanded to give
\begin{equation}
\begin{array}{ccc}
 
 \varphi_i(\mathbf r)\varphi_j(\mathbf r)&=&\mathrm{exp}-\left(\frac{(\sigma_i^2+\sigma_j^2)\left[\mathbf r^\top\mathbf r-2\mathbf r^\top \frac{\sigma_j^2\boldsymbol\mu_i+\sigma_i^2\boldsymbol\mu_j}{\sigma_i^2+\sigma_j^2}+\frac{(\sigma_j^2\boldsymbol\mu_i+\sigma_i^2\boldsymbol\mu_j)^\top(\sigma_j^2\boldsymbol\mu_i+\sigma_i^2\boldsymbol\mu_j)}{(\sigma_i^2+\sigma_j^2)^2}   \right]  +\frac{\sigma_i^2\sigma_j^2}{\sigma_i^2+\sigma_j^2}(\boldsymbol \mu_i-\boldsymbol\mu_j)^\top(\boldsymbol \mu_i-\boldsymbol\mu_j) }{\sigma_i^2\sigma_j^2}\right)\\
&=&\mathrm{exp}\left(-\frac{(\sigma_i^2+\sigma_j^2)\left[(\mathbf r-\frac{\sigma_j^2\boldsymbol\mu_i+\sigma_i^2\boldsymbol\mu_j}{\sigma_i^2+\sigma_j^2})^\top(\mathbf r-\frac{\sigma_j^2\boldsymbol\mu_i+\sigma_i^2\boldsymbol\mu_j}{\sigma_i^2+\sigma_j^2})\right]  }{\sigma_i^2\sigma_j^2}\right)
\times\mathrm{exp}\left(-\frac{(\boldsymbol \mu_i-\boldsymbol\mu_j)^\top(\boldsymbol \mu_i-\boldsymbol\mu_j)}{\sigma_i^2+\sigma_j^2}\right)
\end{array}
\end{equation}
therefore we have
\begin{equation}
 \varphi_i(\mathbf r)\varphi_j(\mathbf r)=c_{i,j}\times\mathrm{exp}\left({-\frac{1}{\sigma^2} (\mathbf r-\boldsymbol \mu)^\top(\mathbf r-\boldsymbol\mu)}\right)
\end{equation}
where
\begin{equation}
 c_{i,j}=\mathrm{exp}\left(-\frac{(\boldsymbol \mu_i-\boldsymbol\mu_j)^\top(\boldsymbol \mu_i-\boldsymbol\mu_j)}{\sigma_i^2+\sigma_j^2}\right) \quad \sigma^2=\frac{\sigma_i^2\sigma_j^2}{\sigma_i^2+\sigma_j^2}
\end{equation}
and
\begin{equation}
 \boldsymbol\mu=\frac{\sigma_j^2\boldsymbol\mu_i+\sigma_i^2\boldsymbol\mu_j}{\sigma_i^2+\sigma_j^2}
\end{equation}
\section*{Derivative of the firing rate}\label{sec:FiringrateDerivative} 
Here we find the derivative of the activation function which is used to compute  $\nabla q$. The sigmoidal activation function which relates firing rate of the presynaptic neurons to the post-synaptic membrane potential is given by
\begin{equation}
	\label{ActivationFunction} f\left( v\left( \mathbf{r}', t \right) \right) = \frac{1}{1 + \exp \left( \varsigma \left( v_0 - v\left(\mathbf{r}',t\right) \right) \right)}. 
\end{equation}
Derivative of the sigmoidal activation function can be written in a simple form as
\begin{eqnarray}
 \frac{df}{dv}&=& \frac{\varsigma}{\left(1 + \exp \left( \varsigma \left( v_0 - v\left(\mathbf{r}',t\right) \right) \right)\right)^2} \times \exp \left( \varsigma \left( v_0 - v\left(\mathbf{r}',t\right) \right) \right) \nonumber \\
&=&\frac{\varsigma}{1 + \exp \left( \varsigma \left( v_0 - v\left(\mathbf{r}',t\right) \right) \right)} \times \left(1-\frac{1}{1 + \exp \left( \varsigma \left( v_0 - v\left(\mathbf{r}',t\right) \right) \right)}\right) \nonumber \\
&=& \varsigma f(\boldsymbol \phi^\top(\mathbf r')\mathbf {x}_t)\left( 1-f( \boldsymbol \phi^\top(\mathbf r')\mathbf {x}_t)\right)
\end{eqnarray}
\section*{$\Xi$-variables}\label{sec:Xivariables} 
In this section, we provide derivation for $\Xi$-variables, which we use in the M-step. From equation 47 of the main text we have
\begin{eqnarray}\label{eq:Qfunction}
  \ln p(\mathbf x_{t+1} | \mathbf x_t;\boldsymbol\theta,\xi)&=&\ln \alpha-\mathbf x_{t+1}^\top\boldsymbol\Sigma_e^{-1}\mathbf x_{t+1}+2\mathbf x_{t+1}^\top\boldsymbol\Sigma_e^{-1}q( \mathbf x_t)\boldsymbol\theta+2\xi \mathrm{tr} \left\lbrace \mathbf x_t\mathbf x_{t+1}^\top\boldsymbol\Sigma_e^{-1}\right\rbrace \nonumber \\
&&-\boldsymbol\theta^\top q^\top(\mathbf x_t)\boldsymbol\Sigma_e^{-1}q(\mathbf x_t)\boldsymbol\theta-2\xi \mathbf x_t^\top\boldsymbol\Sigma_e^{-1}q(\mathbf x_t)\boldsymbol\theta-\xi^2\mathrm{tr}\left\lbrace \mathbf x_t \mathbf x_t^\top\boldsymbol\Sigma_e^{-1}\right\rbrace. 
\end{eqnarray}
substituting for $q(\mathbf x_t)$ using the approximation given in equation 40 of the main text we calculate each $\Xi$-variable as following
\subsection*{Calculating $\Xi_0$}
\begin{eqnarray}\label{eq:Xi0Derivation1}
 \mathbf x_{t+1}^\top\boldsymbol\Sigma_e^{-1}q( \mathbf x_t) &\approx&  \mathbf x_{t+1}^\top\boldsymbol\Sigma_e^{-1}\left[q(\mathbf {\hat x}_t)+\int_\Omega \boldsymbol{\Psi}(\mathbf{r}')\boldsymbol \phi^\top(\mathbf r') (\mathbf x_t - \mathbf  {\hat x}_t)f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}'\right] \nonumber \\
&=&\mathbf x_{t+1}^\top\boldsymbol\Sigma_e^{-1}q(\mathbf {\hat x}_t)+\mathbf x_{t+1}^\top\boldsymbol\Sigma_e^{-1}\int_\Omega \boldsymbol{\Psi}(\mathbf{r}')\boldsymbol \phi^\top(\mathbf r') (\mathbf x_t - \mathbf  {\hat x}_t)f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}'
\end{eqnarray}
noting that $\phi^\top(\mathbf r') (\mathbf x_t - \mathbf  {\hat x}_t)$ is a scalar we can write \ref{eq:Xi0Derivation1} as 
\begin{eqnarray}\label{eq:Xi0Derivation2}
 \mathbf x_{t+1}^\top\boldsymbol\Sigma_e^{-1}q( \mathbf x_t) &\approx& \mathbf x_{t+1}^\top\boldsymbol\Sigma_e^{-1}q(\mathbf {\hat x}_t)+\int_\Omega \boldsymbol \phi^\top(\mathbf r') (\mathbf x_t - \mathbf  {\hat x}_t)\mathbf x_{t+1}^\top\boldsymbol\Sigma_e^{-1}    \boldsymbol{\Psi}(\mathbf{r}')f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}'
\end{eqnarray}
taking expected value of \ref{eq:Xi0Derivation2} we get 
\begin{eqnarray}\label{eq:Xi0Derivation3}
 \mathbf E_{\boldsymbol (\theta',\xi')}\left[\mathbf x_{t+1}^\top\boldsymbol\Sigma_e^{-1}q( \mathbf x_t)\right] &\approx& \mathbf E_{\boldsymbol (\theta',\xi')}\left[\mathbf x_{t+1}^\top\right]\boldsymbol\Sigma_e^{-1}q(\mathbf {\hat x}_t)+\int_\Omega \boldsymbol \phi^\top(\mathbf r')  \mathbf E_{\boldsymbol (\theta',\xi')}\left[(\mathbf x_t - \mathbf  {\hat x}_t)\mathbf x_{t+1}^\top\right]\boldsymbol\Sigma_e^{-1}    \boldsymbol{\Psi}(\mathbf{r}')f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}' \nonumber \\
&=&\mathbf {\hat x}_{t+1}^\top\boldsymbol\Sigma_e^{-1}q(\mathbf {\hat x}_t)+\int_\Omega \boldsymbol \phi^\top(\mathbf r') \mathbf M_{t+1}\boldsymbol\Sigma_e^{-1}    \boldsymbol{\Psi}(\mathbf{r}')f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}'
\end{eqnarray}
summing over $t \in \left\lbrace 0, \dots, T-1\right\rbrace $ we get
\begin{equation}
\Xi_0=\sum_{t=0}^{T-1}\left[ \mathbf{\hat x}_{t+1}^\top\boldsymbol\Sigma_e^{-1}q(\mathbf{\hat x}_t)+\int_\Omega\boldsymbol \phi^\top(\mathbf r') \mathbf M_{t+1} \boldsymbol\Sigma_e^{-1}  \boldsymbol{\Psi}(\mathbf{r}') f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}'\right] \\	
\end{equation}
\subsection*{Calculating $\Xi_1$}
We have
\begin{equation}\label{eq:Xi1}
 \Xi_1=\mathbf E_{(\theta',\xi')}\left[\sum_{t=0}^{T-1}\mathbf x_t\mathbf x_{t+1}^\top\right]
\end{equation}
To find an expression for $\Xi_1$ in terms of smoother outputs we start by expanding the cross-covariance matrix as following
\begin{eqnarray}
 \mathbf M_{t+1}&=&\mathbf E_{(\theta',\xi')}\left[(\mathbf x_t-\mathbf{\hat x}_t)(\mathbf x_{t+1}-\mathbf{\hat x}_{t+1})^\top\right] \nonumber \\
&=&\mathbf E_{(\theta',\xi')}\left[\mathbf x_t\mathbf x_{t+1}^\top\right]-\mathbf E_{(\theta',\xi')}\left[\mathbf x_t\mathbf{\hat x}_{t+1}^\top\right]-\mathbf E_{(\theta',\xi')}\left[\mathbf{\hat x}_t\mathbf x_{t+1}^\top\right]+\mathbf E_{(\theta',\xi')}\left[\mathbf{\hat x}_t\mathbf{\hat x}_{t+1}^\top\right] \nonumber \\
&=&\mathbf E_{(\theta',\xi')}\left[\mathbf x_t\mathbf x_{t+1}^\top\right]-\mathbf {\hat x}_t\mathbf{\hat x}_{t+1}^\top-\mathbf {\hat x}_t\mathbf{\hat x}_{t+1}^\top+\mathbf {\hat x}_t\mathbf{\hat x}_{t+1}^\top \nonumber \\
&=&\mathbf E_{(\theta',\xi')}\left[\mathbf x_t\mathbf x_{t+1}^\top\right]-\mathbf {\hat x}_t\mathbf{\hat x}_{t+1}^\top
\end{eqnarray}
therefore we can write
\begin{equation}\label{eq:Xi1derivation1}
 \mathbf E_{(\theta',\xi')}\left[\mathbf x_t\mathbf x_{t+1}^\top\right]=\mathbf M_{t+1}+\mathbf {\hat x}_t\mathbf{\hat x}_{t+1}^\top
\end{equation}
substituting \ref{eq:Xi1derivation1} in \ref{eq:Xi1} we get
\begin{equation}
 \Xi_1=\sum_{t=0}^{T-1}\left(\mathbf M_{t+1}+\mathbf{\hat x}_t\mathbf{\hat x}_{t+1}^\top\right)
\end{equation}
\subsection*{Calculating $\Xi_2$}
\begin{eqnarray}\label{eq:Xi2derivation1}
 q^\top(\mathbf x_t)\boldsymbol\Sigma_e^{-1}q(\mathbf x_t)&\approx& \left[ q(\mathbf {\hat x}_t)+\int_\Omega \boldsymbol{\Psi}(\mathbf{r}')\boldsymbol \phi^\top(\mathbf r') (\mathbf x_t - \mathbf  {\hat x}_t)f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}'\right]^\top  \times \boldsymbol\Sigma_e^{-1}\nonumber \\
&\times&\left[ q(\mathbf {\hat x}_t)+\int_\Omega \boldsymbol{\Psi}(\mathbf{r}')\boldsymbol \phi^\top(\mathbf r') (\mathbf x_t - \mathbf  {\hat x}_t)f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}'\right] \nonumber \\
&=&q^\top(\mathbf {\hat x}_t)\boldsymbol\Sigma_e^{-1}q(\mathbf {\hat x}_t)+q^\top(\mathbf {\hat x}_t)\int_\Omega \boldsymbol{\Psi}(\mathbf{r}')\boldsymbol \phi^\top(\mathbf r') (\mathbf x_t - \mathbf  {\hat x}_t)f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}'\nonumber\\
&+&\int_\Omega \boldsymbol{\Psi}^\top(\mathbf{r}')\boldsymbol \phi^\top(\mathbf r') (\mathbf x_t - \mathbf  {\hat x}_t)f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}'\boldsymbol\Sigma_e^{-1}q(\mathbf {\hat x}_t) \nonumber \\
&+&\int_\Omega \boldsymbol{\Psi}^\top(\mathbf{r}')\boldsymbol \phi^\top(\mathbf r') (\mathbf x_t - \mathbf  {\hat x}_t)f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}' \times \boldsymbol  \Sigma_e^{-1} \times \int_\Omega \boldsymbol{\Psi}(\mathbf{r}')\boldsymbol \phi^\top(\mathbf r') (\mathbf x_t - \mathbf  {\hat x}_t)f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}' \nonumber \\
&&
\end{eqnarray}
 The last term on the right hand side of equation \ref{eq:Xi2derivation1} can be rewritten as
\begin{eqnarray}
 \int_\Omega \boldsymbol{\Psi}^\top(\mathbf{r}') \boldsymbol\Sigma_e^{-1}f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) \boldsymbol \phi^\top(\mathbf r')(\mathbf x_t - \mathbf  {\hat x}_t)d\mathbf{r}' \times\int_\Omega  (\mathbf x_t - \mathbf  {\hat x}_t)^\top\boldsymbol \phi(\mathbf r') \boldsymbol{\Psi}(\mathbf{r}')f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}'&& \nonumber \\
=\begin{bmatrix} \int_{\Omega} \boldsymbol \Psi^\top(\mathbf r')\boldsymbol \Sigma_e^{-1}\phi_1(\mathbf r')f'(\boldsymbol\phi^\top(\mathbf r')\mathbf {\hat x}_t)d\mathbf r' &  \dots & \int_{\Omega} \boldsymbol \Psi^\top(\mathbf r')\boldsymbol \Sigma_e^{-1}\phi_i(\mathbf r')f'(\boldsymbol\phi^\top(\mathbf r')\mathbf {\hat x}_t)d\mathbf r'\end{bmatrix}(\mathbf x_t - \mathbf  {\hat x}_t) && \nonumber \\
\times (\mathbf x_t - \mathbf  {\hat x}_t)^\top \begin{bmatrix}\int_{\Omega} \boldsymbol \Psi(\mathbf r')\phi_1(\mathbf r')f'(\boldsymbol\phi^\top(\mathbf r')\mathbf {\hat x}_t)d\mathbf r' \\  \vdots \\ \int_{\Omega} \boldsymbol \Psi(\mathbf r')\phi_i(\mathbf r')f'(\boldsymbol\phi^\top(\mathbf r')\mathbf {\hat x}_t)d\mathbf r'\end{bmatrix}&& \nonumber \\
\end{eqnarray}
therefore \ref{eq:Xi2derivation1} can be written as
\begin{eqnarray}\label{eq:Xi2derivation2}
  q^\top(\mathbf x_t)\boldsymbol\Sigma_e^{-1}q(\mathbf x_t)&\approx&q^\top(\mathbf {\hat x}_t)\boldsymbol\Sigma_e^{-1}q(\mathbf {\hat x}_t)+\Lambda_t(\mathbf r)(\mathbf x_t - \mathbf  {\hat x}_t) (\mathbf x_t - \mathbf  {\hat x}_t)^\top\tilde{\Lambda}_t(\mathbf r)+\tilde{q}(\mathbf x_t)
\end{eqnarray}
where $\Lambda_t(\mathbf r)$ and $\tilde{\Lambda}_t(\mathbf r)$ are defined in equations (54-57) of the main text, and  
\begin{eqnarray}\label{eq:qtilde}
 \tilde{q}(\mathbf x_t)&=&q^\top(\mathbf {\hat x}_t)\int_\Omega \boldsymbol{\Psi}(\mathbf{r}')\boldsymbol \phi^\top(\mathbf r') (\mathbf x_t - \mathbf  {\hat x}_t)f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}'\nonumber\\
&+&\int_\Omega \boldsymbol{\Psi}^\top(\mathbf{r}')\boldsymbol \phi^\top(\mathbf r') (\mathbf x_t - \mathbf  {\hat x}_t)f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}'\boldsymbol\Sigma_e^{-1}q(\mathbf {\hat x}_t)
\end{eqnarray}
taking expectation from \ref{eq:Xi2derivation2} we have 
\begin{equation}\label{eq:Xi2derivation3}
\mathbf E_{(\theta',\xi')}\left[ q^\top(\mathbf x_t)\boldsymbol\Sigma_e^{-1}q(\mathbf x_t)\right]\approx q^\top(\mathbf {\hat x}_t)\boldsymbol\Sigma_e^{-1}q(\mathbf {\hat x}_t)  +\Lambda_t(\mathbf r)\mathbf E_{(\theta',\xi')}\left[  (\mathbf x_t - \mathbf  {\hat x}_t) (\mathbf x_t - \mathbf  {\hat x}_t)^\top\right]\tilde{\Lambda}_t(\mathbf r)
\end{equation}


Note that the expectation of $\tilde{q}(\mathbf x_t)$ becomes zero since $\mathbf E_{(\theta',\xi')}\left[(\mathbf x_t - \mathbf  {\hat x}_t)\right]= \mathbf 0$, and hence
\begin{equation}
 \Xi_2= \sum_{t=0}^{T-1}\left[q^\top(\mathbf{\hat x}_t)\boldsymbol\Sigma_e^{-1}q(\mathbf{\hat x}_t)+\Lambda_t(\mathbf r)\mathbf P_t \tilde{\Lambda}_t(\mathbf r)\right]
\end{equation}
\subsection*{Calculating $\Xi_3$}
\begin{eqnarray}\label{eq:Xi3derivation1}
 \mathbf x_t^\top\boldsymbol\Sigma_e^{-1}q(\mathbf x_t)&\approx&\mathbf x_t^\top\boldsymbol\Sigma_e^{-1}\left[q(\mathbf {\hat x}_t)+\int_\Omega \boldsymbol{\Psi}(\mathbf{r}')\boldsymbol \phi^\top(\mathbf r') (\mathbf x_t - \mathbf  {\hat x}_t)f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}'\right] \nonumber\\
&=&\mathbf x_t^\top\boldsymbol\Sigma_e^{-1}q(\mathbf {\hat x}_t)+\mathbf x_t^\top\boldsymbol\Sigma_e^{-1}\int_\Omega \boldsymbol{\Psi}(\mathbf{r}')\boldsymbol \phi^\top(\mathbf r') (\mathbf x_t - \mathbf  {\hat x}_t)f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}' \nonumber \\
&=&\mathbf x_t^\top\boldsymbol\Sigma_e^{-1}q(\mathbf {\hat x}_t)+\int_\Omega \boldsymbol \phi^\top(\mathbf r') (\mathbf x_t - \mathbf  {\hat x}_t)\mathbf x_t^\top\boldsymbol\Sigma_e^{-1}\boldsymbol{\Psi}(\mathbf{r}')f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}'
\end{eqnarray}
taking expected value of \ref{eq:Xi3derivation1} we get
\begin{eqnarray}\label{eq:Xi3derivation2}
\mathbf E_{(\theta',\xi')}\left[\mathbf x_t^\top\boldsymbol\Sigma_e^{-1}q(\mathbf x_t)\right]&\approx&\mathbf E_{(\theta',\xi')}\left[\mathbf x_t^\top\right]\boldsymbol\Sigma_e^{-1}+\int_\Omega \boldsymbol \phi^\top(\mathbf r') \mathbf E_{(\theta',\xi')}\left[(\mathbf x_t - \mathbf  {\hat x}_t)\mathbf x_t^\top\right]\boldsymbol\Sigma_e^{-1}\boldsymbol{\Psi}(\mathbf{r}')f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}' \nonumber \\
&=&\mathbf{ \hat x}_t^\top\boldsymbol\Sigma_e^{-1}+\int_\Omega \boldsymbol \phi^\top(\mathbf r') \mathbf P_t\boldsymbol\Sigma_e^{-1}\boldsymbol{\Psi}(\mathbf{r}')f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}'
\end{eqnarray}
summing over $t \in \left\lbrace 0, \dots, T-1\right\rbrace $ we get
\begin{equation}
\Xi_3=\sum_{t=0}^{T-1}\left[\mathbf{ \hat x}_t^\top\boldsymbol\Sigma_e^{-1}+\int_\Omega \boldsymbol \phi^\top(\mathbf r') \mathbf P_t\boldsymbol\Sigma_e^{-1}\boldsymbol{\Psi}(\mathbf{r}')f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}' \right] \\	
\end{equation}
\subsection*{Calculating $\Xi_4$}
We have
\begin{equation}\label{eq:Xi4}
 \Xi_4=\mathbf E_{(\theta',\xi')}\left[\sum_{t=0}^{T-1}\mathbf x_t\mathbf x_{t}^\top\right]
\end{equation}
To find an expression for $\Xi_4$ in terms of smoother outputs we start by expanding the covariance matrix as following
\begin{eqnarray}
 \mathbf P_{t}&=&\mathbf E_{(\theta',\xi')}\left[(\mathbf x_t-\mathbf{\hat x}_t)(\mathbf x_{t}-\mathbf{\hat x}_{t})^\top\right] \nonumber \\
&=&\mathbf E_{(\theta',\xi')}\left[\mathbf x_t\mathbf x_{t}^\top\right]-\mathbf E_{(\theta',\xi')}\left[\mathbf x_t\mathbf{\hat x}_{t}^\top\right]-\mathbf E_{(\theta',\xi')}\left[\mathbf{\hat x}_t\mathbf x_{t}^\top\right]+\mathbf E_{(\theta',\xi')}\left[\mathbf{\hat x}_t\mathbf{\hat x}_{t}^\top\right] \nonumber \\
&=&\mathbf E_{(\theta',\xi')}\left[\mathbf x_t\mathbf x_{t}^\top\right]-\mathbf {\hat x}_t\mathbf{\hat x}_{t}^\top-\mathbf {\hat x}_t\mathbf{\hat x}_{t}^\top+\mathbf {\hat x}_t\mathbf{\hat x}_{t}^\top \nonumber \\
&=&\mathbf E_{(\theta',\xi')}\left[\mathbf x_t\mathbf x_{t}^\top\right]-\mathbf {\hat x}_t\mathbf{\hat x}_{t}^\top
\end{eqnarray}
therefore we can write
\begin{equation}\label{eq:Xi4derivation1}
 \mathbf E_{(\theta',\xi')}\left[\mathbf x_t\mathbf x_{t}^\top\right]=\mathbf P_{t}+\mathbf {\hat x}_t\mathbf{\hat x}_{t}^\top
\end{equation}
substituting \ref{eq:Xi4derivation1} in \ref{eq:Xi4} we get
\begin{equation}
 \Xi_4=\sum_{t=0}^{T-1}\left(\mathbf P_{t}+\mathbf{\hat x}_t\mathbf{\hat x}_{t}^\top\right)
\end{equation}
\section*{$\sigma_e^2$ Estimation}\label{sec:sigmaeEstimation} 
we have
\begin{equation}\label{eq:qTaylor}
 q(\mathbf x_t) \approx q(\mathbf {\hat x}_t)+\int_\Omega \boldsymbol{\Psi}(\mathbf{r}')\boldsymbol \phi^\top(\mathbf r') (\mathbf x_t - \mathbf  {\hat x}_t)f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}'
\end{equation}
\begin{eqnarray}
 p(\mathbf x_{t+1}, \mathbf y_{t+1};\boldsymbol\Theta)&=& \mid\boldsymbol\Sigma_{\epsilon}\mid^{-\frac{1}{2}} \times  e^{-\frac{1}{2}(\mathbf y_{t+1}-\mathbf C\mathbf  x_{t+1})^\top\boldsymbol\Sigma_{\epsilon}^{-1}(\mathbf y_{t+1}-\mathbf C\mathbf  x_{t+1}) } \nonumber \\
&+&  \mid\boldsymbol\Sigma_e\mid^{-\frac{1}{2}} \times e^{-\frac{1}{2}(\mathbf x_{t+1}-q(\mathbf  x_t)\boldsymbol\theta-\xi  \mathbf x_t)^\top\boldsymbol\Sigma_e^{-1}(\mathbf x_{t+1}-q( \mathbf x_t)\boldsymbol\theta-\xi \mathbf  x_t)}
\end{eqnarray}
by expanding the exponent and taking $2\log$ we get
\begin{eqnarray}\label{eq:Qfunction}
2\ln p(\mathbf x_{t+1} , \mathbf y_{t+1};\boldsymbol\Theta)&=&-\ln \mid\boldsymbol\Sigma_{\epsilon}\mid- (\mathbf y_{t+1}-\mathbf C\mathbf  x_{t+1})^\top\boldsymbol\Sigma_{\epsilon}^{-1}(\mathbf y_{t+1}-\mathbf C\mathbf  x_{t+1})\nonumber \\
&-&\ln \mid\boldsymbol\Sigma_e\mid-\mathbf x_{t+1}^\top\boldsymbol\Sigma_e^{-1}\mathbf x_{t+1}+2\mathbf x_{t+1}^\top\boldsymbol\Sigma_e^{-1}q( \mathbf x_t)\boldsymbol\theta+2\xi \mathbf x_{t+1}^\top\boldsymbol\Sigma_e^{-1}\mathbf x_t\nonumber \\
&-&\boldsymbol\theta^\top q^\top(\mathbf x_t)\boldsymbol\Sigma_e^{-1}q(\mathbf x_t)\boldsymbol\theta-2\xi \mathbf x_t^\top\boldsymbol\Sigma_e^{-1}q(\mathbf x_t)\boldsymbol\theta-\xi^2\mathbf x_t^\top\boldsymbol\Sigma_e^{-1}\mathbf x_t.
\end{eqnarray}
Taking trace and rearranging, using the invariant cyclic permutations property of the trace, this distribution can be written as
\begin{eqnarray}\label{eq:Qfunctionintrace}
  \ln p(\mathbf x_{t+1}, \mathbf y_{t+1};\boldsymbol\Theta)&=& -\ln \mid\boldsymbol\Sigma_{\epsilon}\mid-\mathrm{tr}\left\lbrace\boldsymbol\Sigma_{\epsilon}^{-1}(\mathbf y_{t+1}-\mathbf C\mathbf  x_{t+1}) (\mathbf y_{t+1}-\mathbf C\mathbf  x_{t+1})^\top\right\rbrace   \nonumber \\
&-&\ln \mid\boldsymbol\Sigma_e\mid-\mathrm{tr}\left\lbrace\mathbf x_{t+1}\mathbf x_{t+1}^\top\boldsymbol\Sigma_e^{-1}\right\rbrace+2\mathbf x_{t+1}^\top\boldsymbol\Sigma_e^{-1}q( \mathbf x_t)\boldsymbol\theta+2\xi \mathrm{tr} \left\lbrace \mathbf x_t\mathbf x_{t+1}^\top\boldsymbol\Sigma_e^{-1}\right\rbrace \nonumber \\
&&-\boldsymbol\theta^\top q^\top(\mathbf x_t)\boldsymbol\Sigma_e^{-1}q(\mathbf x_t)\boldsymbol\theta-2\xi \mathbf x_t^\top\boldsymbol\Sigma_e^{-1}q(\mathbf x_t)\boldsymbol\theta-\xi^2\mathrm{tr}\left\lbrace \mathbf x_t \mathbf x_t^\top\boldsymbol\Sigma_e^{-1}\right\rbrace. 
\end{eqnarray}
Substituting \ref{eq:qTaylor} in \ref{eq:Qfunctionintrace} and taking the expectation of the log likelihood function for all time instants gives an approximate to the lower-bound that needs to be maximised to gain optimal parameter estimates. We define $\boldsymbol\Sigma_e=\sigma_e^2\tilde{\boldsymbol\Sigma}_e$. Therefore $\mathcal Q$-function can be approximated as  
\begin{eqnarray}\label{eq:Voldermont}
 \mathcal Q(\boldsymbol \Theta,\boldsymbol\Theta')&\approx& -(T-1)\ln \mid\boldsymbol\Sigma_{\epsilon}\mid-\mathrm{tr}\left\lbrace\boldsymbol\Sigma_{\epsilon}^{-1}\sum_{t=0}^{T-1}\left[ (\mathbf y_{t+1}-\mathbf C\mathbf{\hat{x}}_{t+1}) (\mathbf y_{t+1}-\mathbf C\mathbf{\hat{x}}_{t+1})^\top+\mathbf C \mathbf P_{t+1}\mathbf C^\top\right] \right\rbrace\nonumber \\
&-&(T-1)\ln \mid\sigma_e^2\tilde{\boldsymbol\Sigma}_e\mid-\frac{1}{\sigma_e^2}\mathrm{tr}\left\lbrace \Xi'_0 \tilde{\boldsymbol\Sigma}_e^{-1}\right\rbrace +2\frac{1}{\sigma_e^2}\Xi_0\boldsymbol\theta+
\frac{2\xi}{\sigma_e^2} \mathrm{tr}\left\lbrace \Xi_1 \tilde{\boldsymbol\Sigma}_e^{-1}\right\rbrace \nonumber \\
&-&\frac{1}{\sigma_e^2}\boldsymbol\theta^\top \Xi_2\boldsymbol\theta-\frac{2\xi}{\sigma_e^2} \Xi_3 \boldsymbol\theta -  \frac{\xi^2}{\sigma_e^2}\mathrm{tr} \left\lbrace\Xi_4\tilde{\boldsymbol\Sigma}_e^{-1} \right\rbrace 
\end{eqnarray}
where 
\begin{align}
	\Xi'_0&=\mathbf E_{\Theta'}\left[\sum_{t=0}^{T-1}\mathbf x_{t+1}\mathbf x_{t+1}^\top\right]=\sum_{t=0}^{T-1}\left(\mathbf P_{t+1}+\mathbf{\hat x}_{t+1}\mathbf{\hat x}_{t+1}^\top\right)\label{eq:def of Xi'0} \\
\Xi_0&=\sum_{t=0}^{T-1}\left[ \mathbf{\hat x}_{t+1}^\top\tilde{\boldsymbol\Sigma}_e^{-1}q(\mathbf{\hat x}_t)+\int_\Omega\boldsymbol \phi^\top(\mathbf r') \mathbf M_{t+1} \tilde{\boldsymbol\Sigma}_e^{-1} \boldsymbol{\Psi}(\mathbf{r}') f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}'\right] \\	
\Xi_1&=\mathbf E_{\Theta'}\left[\sum_{t=0}^{T-1}\mathbf x_t\mathbf x_{t+1}^\top\right]=\sum_{t=0}^{T-1}\left(\mathbf M_{t+1}+\mathbf{\hat x}_t\mathbf{\hat x}_{t+1}^\top\right) \\
\Xi_2&=\sum_{t=0}^{T-1}\left[q^\top(\mathbf{\hat x}_t)\tilde{\boldsymbol\Sigma}_e^{-1}q(\mathbf{\hat x}_t)+\Lambda_t(\mathbf r)\mathbf P_t \tilde{\Lambda}_t(\mathbf r)\right] \\
 \Xi_3&=\sum_{t=0}^{T-1}\left[ \mathbf{\hat x}_{t}^\top\tilde{\boldsymbol\Sigma}_e^{-1}q(\mathbf{\hat x}_t)+\int_\Omega\boldsymbol \phi^\top(\mathbf r') \mathbf P_t \tilde{\boldsymbol\Sigma}_e^{-1}  \boldsymbol{\Psi}(\mathbf{r}') f'(\boldsymbol \phi^\top(\mathbf r')\mathbf {\hat x}_t) d\mathbf{r}'\right] \\
 \Xi_4&=\mathbf E_{\Theta'}\left[\sum_{t=0}^{T-1}\mathbf x_t\mathbf x_{t}^\top\right]=\sum_{t=0}^{T-1}\left(\mathbf P_t+\mathbf{\hat x}_t\mathbf{\hat x}_t^\top\right)
\end{align}
and
\begin{align}
	 \Lambda_t(\mathbf r)&=\begin{bmatrix}\boldsymbol \lambda_t^{(1)}(\mathbf r) & \boldsymbol \lambda_t^{(2)}(\mathbf r)& \dots &\boldsymbol \lambda_t^{(i)}(\mathbf r)\end{bmatrix} \\
	 \boldsymbol\lambda_t^{(i)}(\mathbf r)&=\int_{\Omega} \boldsymbol \Psi^\top(\mathbf r')\tilde{\boldsymbol\Sigma}_e^{-1}\phi_i(\mathbf r')f'(\boldsymbol\phi^\top(\mathbf r')\mathbf {\hat x}_t)d\mathbf r'\\
	\tilde{\Lambda}_t(\mathbf r)&=\begin{bmatrix}\tilde{\boldsymbol \lambda}_t^{(1)}(\mathbf r) \\ \tilde{\boldsymbol \lambda}_t^{(2)}(\mathbf r) \\ \vdots \\ \tilde{\boldsymbol \lambda}_t^{(i)}(\mathbf r)\end{bmatrix} \\
	 \tilde{\boldsymbol \lambda}_t^{(i)}(\mathbf r)&=\int_{\Omega} \boldsymbol \Psi(\mathbf r')\phi_i(\mathbf r')f'(\boldsymbol\phi^\top(\mathbf r')\mathbf {\hat x}_t)d\mathbf r'
\end{align}
It should be noted that the second term in equation \ref{eq:Voldermont} is obtained by adding and subtracting $\mathbf C \mathbf{\hat{x}}_t \mathbf{\hat{x}}_t^\top \mathbf C^\top$ to the expectation, $\mathbf E_{\boldsymbol\Theta'}\left[ .\right] $. Given the state estimates, $\mathbf {\hat x^{b}}_t$ the state covariance $\mathbf P_t^b$ and cross-covariance $\mathbf M_t^b$ , the $\Xi$-variables can be computed directly.

When taking the derivative of equation~\ref{eq:Voldermont}, the constant $\beta$ described in equation~\ref{eq:def of beta} will disappear. Differntiating with respect to $\boldsymbol\theta$ we have
\begin{equation}\label{eq:Qpartialtheta}
 \frac{\partial \mathcal Q}{\partial \boldsymbol\theta}=2\Xi_0-\boldsymbol\theta^\top(\Xi_2^\top+\Xi_2)-2\xi\Xi_3
\end{equation}
noting that $\Xi_2$ is symmetric and equating \ref{eq:Qpartialtheta} to the zero vector we get
\begin{equation}\label{eq:theta}
 \boldsymbol \theta=\Xi_2^{-1}\left(\Xi_0^\top-\xi\Xi_3^\top \right)
\end{equation}
similarly differentiating with respect to $\xi$ we have
\begin{equation}\label{eq:Qpartialxi}
 \frac{\partial \mathcal Q}{\partial \xi}=2tr\left\lbrace \Xi_1 \boldsymbol\Sigma_e^{-1}\right\rbrace -2 \Xi_3 \boldsymbol\theta - 2\xi tr \left\lbrace\Xi_4\boldsymbol\Sigma_e^{-1} \right\rbrace
\end{equation}
substituting \ref{eq:theta} in \ref{eq:Qpartialxi} and equating to zero we get
\begin{equation}
 \xi=\frac{tr\left\lbrace \Xi_1 \tilde{\boldsymbol\Sigma}_e^{-1}\right\rbrace-\Xi_3\Xi_2^{-1}\Xi_0^\top}{tr\left\lbrace \Xi_4 \tilde{\boldsymbol\Sigma}_e^{-1}\right\rbrace-\Xi_3\Xi_2^{-1}\Xi_3^\top}
\end{equation}
Rewrite equation~\ref{eq:Voldermont} as
\begin{equation}
 \mathcal Q(\boldsymbol \Theta,\boldsymbol\Theta')\propto-(T-1)n_y\ln\sigma^2_{\epsilon}-\frac{1}{\sigma_{\epsilon}^2}\mathrm{tr}\left\lbrace\sum_{t=0}^{T-1}\left[ (\mathbf y_{t+1}-\mathbf C\mathbf{\hat{x}}_{t+1}) (\mathbf y_{t+1}-\mathbf C\mathbf{\hat{x}}_{t+1})^\top+\mathbf C \mathbf P_{t+1}\mathbf C^\top\right] \right\rbrace
\end{equation}
differentiating with respect to $\sigma_{\epsilon}^2$
\begin{equation}
  \frac{\partial \mathcal Q}{\partial \sigma_{\epsilon}^2}=-(T-1)n_y\frac{1}{\sigma_{\epsilon}^2}+\frac{1}{\sigma_{\epsilon}^4}\mathrm{tr}\left\lbrace\sum_{t=0}^{T-1}\left[ (\mathbf y_{t+1}-\mathbf C\mathbf{\hat{x}}_{t+1}) (\mathbf y_{t+1}-\mathbf C\mathbf{\hat{x}}_{t+1})^\top+\mathbf C \mathbf P_{t+1}\mathbf C^\top\right] \right\rbrace
\end{equation}
setting above to zero and solving for $\sigma_{\epsilon}^2$ we have
\begin{equation}
 \sigma_{\epsilon}^2=\frac{1}{(T-1)n_y}\sum_{t=0}^{T-1}\mathrm{tr}\left\lbrace (\mathbf y_{t+1}-\mathbf C\mathbf{\hat{x}}_{t+1}) (\mathbf y_{t+1}-\mathbf C\mathbf{\hat{x}}_{t+1})^\top+\mathbf C \mathbf P_{t+1}\mathbf C^\top \right\rbrace
\end{equation}
differentiating ~\ref{eq:Voldermont} with respect to $\sigma_e^2$ we have
\begin{eqnarray}
 \frac{\partial \mathcal Q}{\partial \sigma_e^2}&=& -(T-1)n_x\frac{1}{\sigma_e^2}+\frac{1}{\sigma_e^4}\mathrm{tr}\left\lbrace \Xi'_0 \tilde{\boldsymbol\Sigma}_e^{-1}\right\rbrace -2\frac{1}{\sigma_e^4}\Xi_0\boldsymbol\theta-
\frac{2\xi}{\sigma_e^4} \mathrm{tr}\left\lbrace \Xi_1 \tilde{\boldsymbol\Sigma}_e^{-1}\right\rbrace \nonumber \\
&+&\frac{1}{\sigma_e^4}\boldsymbol\theta^\top \Xi_2\boldsymbol\theta+\frac{2\xi}{\sigma_e^4} \Xi_3 \boldsymbol\theta +\frac{\xi^2}{\sigma_e^4}\mathrm{tr} \left\lbrace\Xi_4\tilde{\boldsymbol\Sigma}_e^{-1} \right\rbrace 
\end{eqnarray}
setting above to zero and solving for $\sigma_e^2$ we have
\begin{eqnarray}
\sigma_e^2=\frac{1}{(T-1)n_x}\left[ \mathrm{tr}\left\lbrace \Xi'_0 \tilde{\boldsymbol\Sigma}_e^{-1}\right\rbrace -2\Xi_0\boldsymbol\theta-
2\xi\mathrm{tr}\left\lbrace \Xi_1 \tilde{\boldsymbol\Sigma}_e^{-1}\right\rbrace+\boldsymbol\theta^\top \Xi_2\boldsymbol\theta+2\xi\Xi_3 \boldsymbol\theta +\xi^2\mathrm{tr} \left\lbrace\Xi_4\tilde{\boldsymbol\Sigma}_e^{-1} \right\rbrace \right] 
\end{eqnarray}
\section*{Observation Autocorrelation}\label{sec:ObservAutocor} 
\begin{align}
	R_{y_{t},y_{t}}(\boldsymbol{\tau}) &= \mathbf{E}\left[y_{t}\left(\mathbf{r}_n+\boldsymbol{\tau}\right)y_{t}\left(\mathbf{r}_n\right)\right] \\
	&= \mathbf{E}\left[\left(\int_{\Omega}{ m\left(\mathbf{r}_n + \boldsymbol{\tau} - \mathbf{r}'\right) v_t\left(\mathbf{r}'\right)\, d\mathbf{r}'} + \boldsymbol{\varepsilon}_t\left(\mathbf{r}_n+\boldsymbol{\tau}\right)\right) \left(\int_{\Omega}{ m\left(\mathbf{r}_n - \mathbf{r}''\right) v_{t}\left(\mathbf{r}''\right) \, d\mathbf{r}''} + \boldsymbol{\varepsilon}_{t}\left(\mathbf{r}_n\right)\right) \right]\\
	&=\mathbf{E}\left[\int_{\Omega}{ m\left(\mathbf{r}_n + \boldsymbol{\tau} - \mathbf{r}'\right) v_t\left(\mathbf{r}'\right)\, d\mathbf{r}'} \int_{\Omega}{ m\left(\mathbf{r}_n - \mathbf{r}''\right) v_{t}\left(\mathbf{r}''\right) \, d\mathbf{r}''}\right]\\
	&=\iint_{\Omega}{ m\left(\mathbf{r}_n + \boldsymbol{\tau} - \mathbf{r}'\right) m\left(\mathbf{r}_n - \mathbf{r}''\right) \mathbf{E}\left[v_t\left(\mathbf{r}'\right) v_{t}\left(\mathbf{r}''\right)\right]\, d\mathbf{r}'}{ \, d\mathbf{r}''}\\
	&=\sigma_d\iint_{\Omega}{ m\left(\mathbf{r}_n + \boldsymbol{\tau} - \mathbf{r}'\right) m\left(\mathbf{r}_n - \mathbf{r}''\right)\gamma(\mathbf{r}'-\mathbf{r}'') \, d\mathbf{r}'}{ \, d\mathbf{r}''}\label{eq:ObsCorr}
\end{align}
\section*{Estimation of Connectivity Kernel Support}
The support of the connectivity kernel can be inferred using spatial correlation analysis. The method presented in this paper is based on a similar published method, where the kernel support was estimated using correlation analysis for a linear system described by an IDE~\cite{Scerri2009}. To demonstrate the method for the neural field model, we first define the spatial cross-correlation function between consecutive observations as 
\begin{align}
	R_{y_{t},y_{t+1}}(\boldsymbol{\tau}) &= \mathbf{E}\left[y_{t}\left(\mathbf{r}_n+\boldsymbol{\tau}\right)y_{t+1}\left(\mathbf{r}_n\right)\right] \\
	&= \mathbf{E}\left[\left(\int_{\Omega}{ m\left(\mathbf{r}_n + \boldsymbol{\tau} - \mathbf{r}'\right) v_t\left(\mathbf{r}'\right)\, d\mathbf{r}'} + \boldsymbol{\varepsilon}_t\left(\mathbf{r}_n+\boldsymbol{\tau}\right)\right) \left(\int_{\Omega}{ m\left(\mathbf{r}_n - \mathbf{r}'\right) v_{t+1}\left(\mathbf{r}'\right) \, d\mathbf{r}'} + \boldsymbol{\varepsilon}_{t+1}\left(\mathbf{r}_n\right)\right) \right], \label{eq:ObsXCorr}
\end{align}
where $\mathbf{E}[\cdot]$ is the expected value. Since the observation noise is temporally white and independent of the field, equation~\ref{eq:ObsXCorr} reduces to
\begin{align}
	R_{y_{t},y_{t+1}}(\boldsymbol{\tau}) &= \mathbf{E}\left[\int_{\Omega}{ m\left(\mathbf{r}_n + \boldsymbol{\tau} - \mathbf{r}'\right) v_t\left(\mathbf{r}'\right)\, d\mathbf{r}'}\int_{\Omega}{ m\left(\mathbf{r}_n - \mathbf{r}'\right) v_{t+1}\left(\mathbf{r}'\right)\, d\mathbf{r}'} \right] \\
	&=\mathbf{E}\left[\bar{y}_t\left(\mathbf{r}_n + \boldsymbol{\tau}\right)\int_{\Omega}{ m\left(\mathbf{r}_n - \mathbf{r}'\right) v_{t+1}\left(\mathbf{r}'\right)\, d\mathbf{r}'} \right],
\end{align}
where $\bar{y}_t\left(\mathbf{r}_n + \boldsymbol{\tau}\right)$ is the noise-free observation.

Substituting in equation~\ref{DiscreteTimeModel}  for $v_{t+1}\left(\mathbf{r}\right)$, the cross-correlation function is
\begin{align}
	R_{y_{t},y_{t+1}}(\boldsymbol{\tau}) &= \mathbf{E}\left[\bar{y}_t\left(\mathbf{r}_n + \boldsymbol{\tau}\right) \int_{\Omega}{m\left(\mathbf{r}_n-\mathbf{r}'\right) \left(\xi v_t\left(\mathbf{r}'\right) +T_s \int_\Omega { w\left(\mathbf{r}',\mathbf{r}''\right) f\left(v_t\left(\mathbf{r}''\right)\right)\, d\mathbf{r}''} + e_t\left(\mathbf{r}'\right)\right)\, d\mathbf{r}'} \right] \\	
	 &= \xi\mathbf{E}\left[\bar{y}_t\left(\mathbf{r}_n + \boldsymbol{\tau}\right)\int_{\Omega}{ m\left(\mathbf{r}_n - \mathbf{r}'\right) v_t\left(\mathbf{r}'\right) d\mathbf{r}'} \right] \nonumber \\
	&+ T_s\mathbf{E}\left[\bar{y}_t\left(\mathbf{r}_n + \boldsymbol{\tau}\right) \int_{\Omega} {m\left(\mathbf{r}_n-\mathbf{r}'\right) \int_\Omega { w\left(\mathbf{r}',\mathbf{r}''\right) f\left(v_t\left(\mathbf{r}''\right)\right)\, d\mathbf{r}''}\, d\mathbf{r}'} \right] \nonumber \\
	&+ \mathbf{E}\left[\bar{y}_t\left(\mathbf{r}_n + \boldsymbol{\tau}\right)\int_{\Omega} { m\left(\mathbf{r}_n-\mathbf{r}'\right) e_t \left(\mathbf{r}'\right)\, d\mathbf{r}' } \right]
	\label{eq:spatialxcorr}
\end{align}

The first term on the right hand side of equation~\ref{eq:spatialxcorr} is
\begin{equation}
	\xi\mathbf{E}\left[\bar{y}_t\left(\mathbf{r}_n + \boldsymbol{\tau}\right) \int_{\Omega}{ m\left(\mathbf{r}_n-\mathbf{r}'\right) v_t\left(\mathbf{r}\right) d\mathbf{r}'} \right] = \xi R_{\bar{y}_{t},\bar{y}_{t}}(\boldsymbol{\tau}),
\end{equation}
which is the spatial autocorrelation of the observations scaled by the decay parameter $\xi$. The last term on the right hand side of equation~\ref{eq:spatialxcorr} equates to zero since the disturbance added to the field at time $t$ and assumed to be uncorrelated to the field at time $t$. 

To understand the middle term, the sigmoid activation function, $f(\cdot)$, is approximated by the piecewise function
\begin{equation}
	\hat{f}(v_t(\mathbf{r}')) = \left\{ \begin{array}{ll}
		0, & v_t(\mathbf{r}') \le v_1 \\
		\varsigma v_t(\mathbf{r}'), &  v_1 < v_t(\mathbf{r}') < v_2 \\
		1, & v_t(\mathbf{r}') \ge v_2 \\ 
		\end{array}\right.
\end{equation}
Evaluating the middle term of the RHS of equation~\ref{eq:spatialxcorr} for the case where the field is in the linear region of the nonlinearity gives
\begin{align}
	middle term &= T_s\mathbf{E}\left[ \bar{y}_t\left( \mathbf{r}_n + \boldsymbol{\tau} \right) \int_{\Omega}{ m\left(\mathbf{r}_n-\mathbf{r}'\right)\int_\Omega { w\left(\mathbf{r}',\mathbf{r}''\right) f\left(v_t\left(\mathbf{r}''\right)\right)\, d\mathbf{r}''}\, d\mathbf{r}'}\right]  \\
	&=T_s\mathbf{E}\left[ \bar{y}_t\left( \mathbf{r}_n + \boldsymbol{\tau} \right) \int_{\Omega}{ m\left(\mathbf{r}_n-\mathbf{r}'\right)\int_\Omega { w\left(\mathbf{r}',\mathbf{r}''\right) \varsigma v_t\left(\mathbf{r}''\right)\, d\mathbf{r}''}\, d\mathbf{r}'}\right] \label{eq:preswap}  \\
	&= T_s\varsigma\mathbf{E}\left[ \bar{y}_t\left( \mathbf{r}_n + \boldsymbol{\tau} \right) \int_{\Omega}{ w\left(\mathbf{r}_n,\mathbf{r}'\right) \int_\Omega {  m\left(\mathbf{r}'-\mathbf{r}''\right) v_t\left(\mathbf{r}''\right)\, d\mathbf{r}''}\, d\mathbf{r}'}\right]  \label{eq:postswap} \\
	&= T_s\varsigma\mathbf{E}\left[ \bar{y}_t\left( \mathbf{r}_n + \boldsymbol{\tau} \right) \int_{\Omega}{ w\left(\mathbf{r}_n,\mathbf{r}'\right) \bar{y}_t\left(\mathbf{r}'\right)\, d\mathbf{r}'}\right],	
\end{align}
where the associativity and commutativity algebraic properties of the spatial convolution where used to move from equation~\ref{eq:preswap} to equation~\ref{eq:postswap}.
% 
% Evaluating the middle term for the saturation regions. If $v_t(\mathbf{r}') \le v_1$ then the middle term will equate to zero. If $v_t(\mathbf{r}') \ge v_2$ then we get
% \begin{align}
% 	middle term &= T_s \mathbf{E} \left[ \bar{y}_t\left(\mathbf{r}_n+\boldsymbol{\tau}\right) \int_{\Omega} { m\left(\mathbf{r}_n-\mathbf{r}'\right) \int_\Omega { w\left(\mathbf{r},\mathbf{r}''\right) \, d\mathbf{r}''} \, d\mathbf{r}'} \right] \\
% 	&= T_s a_1 \mathbf{E}\left[ \bar{y}_t \left( \mathbf{r}_n + \boldsymbol{\tau} \right) \int_{\Omega}{ m\left(\mathbf{r}_n - \mathbf{r}'\right)\, d\mathbf{r}'} \right] \\
% 	&= T_s a_1 a_2 \mathbf{E}\left[ \bar{y}_t \left( \mathbf{r}_n + \boldsymbol{\tau} \right) \right],
% \end{align}
% where $a_1$ is the integral of the connectivity kernel and $a_2$ is the integral of the observation kernel.

Under the assumption that the field is in the linear region of the sigmoid for the majority of time then
\begin{equation}\label{eq:approx_xcorr}
	R_{y_{t},y_{t+1}}(\boldsymbol{\tau}) \approx \xi R_{  \bar{y}_{t},\bar{y}_{t} } (\boldsymbol{\tau}) + T_s\varsigma\mathbf{E}\left[ \bar{y}_t\left( \mathbf{r}_n + \boldsymbol{\tau} \right) \int_{\Omega}{ w\left(\mathbf{r}_n,\mathbf{r}'\right) \bar{y}_t\left( \mathbf{r}' \right)\, d\mathbf{r}'}\right].
\end{equation}
The autocorrelation of the noisy observations is
\begin{equation}\label{eq:autocorrelation_of_y}
	R_{y_{t},y_{t}}(\boldsymbol{\tau}) = R_{\bar{y}_{t},\bar{y}_{t} } (\boldsymbol{\tau}) + \delta(\boldsymbol{\tau})\sigma_{\varepsilon}^2,
\end{equation}
where $\delta(\cdot)$ is the Kronecker delta function. Rearranging equation~\ref{eq:autocorrelation_of_y} and substituting it into equation~\ref{eq:approx_xcorr} gives
\begin{equation}
	R_{y_{t},y_{t+1}}(\boldsymbol{\tau}) \approx \xi (R_{y_{t},y_{t}}(\boldsymbol{\tau}) - \delta(\boldsymbol{\tau}) \sigma_{\varepsilon}^2) + T_s\varsigma\mathbf{E}\left[ \bar{y}_t\left( \mathbf{r}_n + \boldsymbol{\tau} \right) \int_{\Omega}{ w\left(\mathbf{r}_n,\mathbf{r}'\right) \bar{y}_t\left( \mathbf{r}' \right)\, d\mathbf{r}'}\right],	
\end{equation}
and
\begin{equation}\label{eq:support_estimator}
	R_{y_{t},y_{t+1}}(\boldsymbol{\tau}) - \xi (R_{y_{t},y_{t}}(\boldsymbol{\tau}) - \delta(\boldsymbol{\tau}) \sigma_{\varepsilon}^2) \approx T_s\varsigma\mathbf{E}\left[ \bar{y}_t\left( \mathbf{r}_n + \boldsymbol{\tau} \right) \int_{\Omega}{ w\left(\mathbf{r}_n,\mathbf{r}'\right) \bar{y}_t\left( \mathbf{r}' \right)\, d\mathbf{r}'}\right].	
\end{equation}
The right hand side of equation~\ref{eq:support_estimator} will have the structure of the connectivity kernel. 

This may hold:
\begin{equation}
	R_{\bar{y}_{t},\bar{y}_{t} } (\boldsymbol{\tau}) = \sigma_d \int_{\Omega}{ m(\mathbf{r}_n+\boldsymbol{\tau}-\mathbf{r}')\int_{\Omega}{ m(\mathbf{r}'_n-\mathbf{r}'') \gamma(\mathbf{r}'-\mathbf{r}'') d\mathbf{r}''} d\mathbf{r}'}.
\end{equation}
If it does then we can estimate the support of the disturbance using the correlation analysis if the bandwidth of the sensor is wider than the bandwidth of the disturbance.\\
the proof of the above\\
\begin{align}
	R_{y_{t},y_{t}}(\boldsymbol{\tau}) &= \mathbf{E}\left[y_{t}\left(\mathbf{r}_n+\boldsymbol{\tau}\right)y_{t}\left(\mathbf{r}_n\right)\right] \\
	&= \mathbf{E}\left[\left(\int_{\Omega}{ m\left(\mathbf{r}_n + \boldsymbol{\tau} - \mathbf{r}'\right) v_t\left(\mathbf{r}'\right)\, d\mathbf{r}'} + \boldsymbol{\varepsilon}_t\left(\mathbf{r}_n+\boldsymbol{\tau}\right)\right) \left(\int_{\Omega}{ m\left(\mathbf{r}_n - \mathbf{r}''\right) v_{t}\left(\mathbf{r}''\right) \, d\mathbf{r}''} + \boldsymbol{\varepsilon}_{t}\left(\mathbf{r}_n\right)\right) \right]\\
	&=\mathbf{E}\left[\int_{\Omega}{ m\left(\mathbf{r}_n + \boldsymbol{\tau} - \mathbf{r}'\right) v_t\left(\mathbf{r}'\right)\, d\mathbf{r}'} \int_{\Omega}{ m\left(\mathbf{r}_n - \mathbf{r}''\right) v_{t}\left(\mathbf{r}''\right) \, d\mathbf{r}''}\right]\\
	&=\iint_{\Omega}{ m\left(\mathbf{r}_n + \boldsymbol{\tau} - \mathbf{r}'\right) m\left(\mathbf{r}_n - \mathbf{r}''\right) \mathbf{E}\left[v_t\left(\mathbf{r}'\right) v_{t}\left(\mathbf{r}''\right)\right]\, d\mathbf{r}'}{ \, d\mathbf{r}''}\\
	&=\sigma_d\iint_{\Omega}{ m\left(\mathbf{r}_n + \boldsymbol{\tau} - \mathbf{r}'\right) m\left(\mathbf{r}_n - \mathbf{r}''\right)\gamma(\mathbf{r}'-\mathbf{r}'') \, d\mathbf{r}'}{ \, d\mathbf{r}''}\label{eq:ObsCorr}
\end{align}

% Therefore we can write
% \begin{equation}
% 	R_{v_{t},v_{t+1}}(\mathbf{\tau}) = \xi R_{v_{t},v_{t}}(\mathbf{\tau}) + T_s R_{v_{t},g_{t}}(\mathbf{\tau})
% \end{equation}
% and
% \begin{equation}\label{eq:xcorr_firing_and_field}
% 	T_s R_{v_{t},g_{t}}(\mathbf{\tau}) = R_{v_{t},v_{t+1}}(\mathbf{\tau})-\xi R_{v_{t},v_{t}}(\mathbf{\tau}).
% \end{equation}
% The spatial cross-correlation function $R_{v_{t},g_{t}}(\mathbf{\tau})$ depends on the shape of the spatial mixing kernel $w\left( \mathbf{r},\mathbf{r}' \right)$. Furthermore, the sign (polarity) of $R_{v_{t},g_{t}}(\mathbf{\tau})$ will be the same as the $w\left( \mathbf{r},\mathbf{r}' \right)$ for a given spatial location since the sigmoid function $f\left( v_t\left( \mathbf{r}' \right) \right) > \mathbf{0}$. Therefore, the support of the kernel can be inferred given the cross-correlation function $R_{v_{t},g_{t}}(\mathbf{\tau})$. The right hand side of equation~\ref{eq:xcorr_firing_and_field} can be calculated from data if $\xi$ is known. However, since $\xi$ is a decay parameter, we know that $\xi \in (0,1)$. Also, if we assume that
% \begin{equation}
% 	\xi R_{v_{t},v_{t}}(\mathbf{\tau}) \gg T_s R_{v_{t},g_{t}}(\mathbf{\tau})
% \end{equation}
% and
% \begin{equation}
% 	R_{v_{t},g_{t}}(\mathbf{0}) > 0,
% \end{equation}
% which corresponds to local excitation, then we can guess $\xi$ by incrementally increasing it from zero and evaluating equation~\ref{eq:xcorr_firing_and_field} until $T_s R_{v_{t},g_{t}}(\mathbf{0}) < 0$. The value of $\xi$ before $T_s R_{v_{t},g_{t}}(\mathbf{0}) < 0$ will provide the approximation.

\subsection*{shannon}
Consider a regular lattice in $\mathbb R^n$, with lattice points $\left\lbrace \Delta J; J\in \mathbb Z^n\right\rbrace$ and where $\Delta$ is the distance between adjacent points. The continuous field $v(\mathbf r)$ can be sampled using a field of Dirac-delta functions, $\delta(\mathbf r)$ located at the lattice points as
\begin{equation}
 v_s(\Delta J)=\sum_{J \in \mathbb Z^n}\delta(\mathbf r-\Delta J)v(\mathbf r)
\end{equation}
taking Fourier transfom of the sampled field $v_s(\Delta J)$ we have
\begin{align}
 V_s(\boldsymbol{\nu})&=\frac{1}{\Delta^n}\sum_{J\in\mathbb Z^n}\delta(\boldsymbol{\nu}-\frac{J}{\Delta})\ast V(\boldsymbol\nu)\\
&=\frac{1}{\Delta^n}V(\boldsymbol\nu)+\frac{1}{\Delta^n}\sum_{J\in\mathbb Z^n\setminus \mathbf \{0\}}V(\boldsymbol{\nu}-\frac{J}{\Delta})
\end{align}
hence,$V_s(\boldsymbol{\nu})$ contains $V(\boldsymbol\nu)$ plus infinitely many copies (aliases) of  $V(\boldsymbol\nu)$ repeated on the regular lattice $\left\lbrace \frac{J}{\Delta}; J\in \mathbb Z^n\right\rbrace$. Given the dynamic field is band-limited with a cut-off frequency $\boldsymbol\nu_c$ in order for $V(\boldsymbol\nu)$ to be disjointed with its aliases the amount of shift $\frac{1}{\Delta}$ must be at least $2\nu_c$, therefore
\begin{equation}\label{ap:Shannon}
 \Delta\le\frac{1}{2\rho\nu_c}
\end{equation}
where $\rho \in \mathbb{R} \ge 1$ is an oversampling parameter. To recover the continuous field, we first introduce a low-pass filter \begin{equation}
F(\boldsymbol \nu)=\begin{cases}
  \Delta^n & |\boldsymbol\nu|\le \boldsymbol\nu_c \\
  0 & \text{otherwise}
\end{cases} 
\end{equation}
if the sampling rule \eqref{ap:Shannon} is satisfied, the original spectrum, $V(\boldsymbol\nu)$ can be recovered using
\begin{equation}
 V(\boldsymbol\nu)=F(\boldsymbol \nu)V_s(\boldsymbol\nu)
\end{equation}
taking inverse Fourier transform we have
\begin{align}
v(\mathbf s)&=f(\mathbf s)\ast v_s(\Delta J) \\
&=\sum_{J \in \mathbb Z^n}f(\mathbf s-\Delta J) v_s(\Delta J)
\end{align}
However many other basis functions can be potentially used for reconstruction, and a continuous field can be reconstructed from the sampled field by the sum of weighted, spatially translated, continuous  basis functions.
\bibliographystyle{plain}
\bibliography{}
\end{document}
